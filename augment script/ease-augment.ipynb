{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11178730,"sourceType":"datasetVersion","datasetId":6963199}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T00:13:40.241591Z","iopub.execute_input":"2025-03-27T00:13:40.241825Z","iopub.status.idle":"2025-03-27T00:13:40.624429Z","shell.execute_reply.started":"2025-03-27T00:13:40.241802Z","shell.execute_reply":"2025-03-27T00:13:40.623349Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/exist2025-all/EXIST2025_dev_task1_3_majority_class_soft.json\n/kaggle/input/exist2025-all/EXIST2025_dev_task1_3_minority_class_hard.json\n/kaggle/input/exist2025-all/EXIST2025_training_task1_3_minority_class_hard.json\n/kaggle/input/exist2025-all/EXIST2025_training.json\n/kaggle/input/exist2025-all/EXIST2025_dev_task1_3_minority_class_soft.json\n/kaggle/input/exist2025-all/EXIST2025_training_task1_3_majority_class_soft.json\n/kaggle/input/exist2025-all/EXIST2025_training_task1_3_majority_class_hard.json\n/kaggle/input/exist2025-all/EXIST2025_training_translated_en.json\n/kaggle/input/exist2025-all/EXIST2025_training_translated_es.json\n/kaggle/input/exist2025-all/EXIST2025_training_task1_3_minority_class_soft.json\n/kaggle/input/exist2025-all/EXIST2025_dev_task1_3_majority_class_hard.json\n/kaggle/input/exist2025-all/EXIST2025_dev.json\n/kaggle/input/exist2025-all/EXIST2025_dev_task1_3_gold_hard.json\n/kaggle/input/exist2025-all/EXIST2025_training_task1_3_gold_soft.json\n/kaggle/input/exist2025-all/EXIST2025_dev_task1_3_gold_soft.json\n/kaggle/input/exist2025-all/EXIST2025_training_task1_3_gold_hard.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install nltk transformers torch tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T00:13:49.508709Z","iopub.execute_input":"2025-03-27T00:13:49.509142Z","iopub.status.idle":"2025-03-27T00:13:54.425436Z","shell.execute_reply.started":"2025-03-27T00:13:49.509101Z","shell.execute_reply":"2025-03-27T00:13:54.424359Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=\"0c5f368f1f51fd942ec7bb3a1c74efb7bdc832d6\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T21:24:47.985588Z","iopub.execute_input":"2025-03-26T21:24:47.985993Z","iopub.status.idle":"2025-03-26T21:24:56.325780Z","shell.execute_reply.started":"2025-03-26T21:24:47.985951Z","shell.execute_reply":"2025-03-26T21:24:56.325066Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmshoaibvohra\u001b[0m (\u001b[33mmshoaibvohra-habib-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import json\nimport torch\nimport nltk\nfrom transformers import DistilBertForSequenceClassification, DistilBertTokenizer\nfrom tqdm import tqdm\nfrom torch.nn.functional import softmax\n\n# Ensure necessary NLTK components are available\nnltk.download(\"punkt\")\n\n# Load the dataset\nfile_path = \"/kaggle/input/exist2025-all/EXIST2025_training_translated_en.json\"\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\n# Load Pretrained DistilBERT Model & Tokenizer (For Label Acquisition)\nmodel_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = DistilBertTokenizer.from_pretrained(model_name)\nmodel = DistilBertForSequenceClassification.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\n# **Step 1: Extracting Units**\ndef extract_units(text):\n    \"\"\"Extracts meaningful sentence units (Facts/Sentences) from text.\"\"\"\n    sentences = nltk.sent_tokenize(text)\n    return sentences if len(sentences) > 1 else [text]  # Ensure at least one unit\n\n# **Step 2: Label Acquisition (Not needed since we're keeping original labels)**\n\n# **Step 3 & 4: Sift & Employ**\naugmented_data = {}\naugmented_count = 0\n\nfor key, value in tqdm(data.items(), desc=\"Applying EASE Augmentation\"):\n    original_text = value[\"tweet\"]\n    extracted_units = extract_units(original_text)\n\n    for i, unit in enumerate(extracted_units):\n        aug_key = f\"{key}_AUG_{i}\"\n        \n        # Create an augmented version while keeping labels the same\n        augmented_data[aug_key] = {\n            \"id_EXIST\": f\"{value['id_EXIST']}_AUG_{i}\",\n            \"tweet\": unit,\n            \"lang\": value[\"lang\"],\n            \"split\": \"AUG_EN\",  # Change split to AUG_EN\n            \"number_annotators\": value[\"number_annotators\"],\n            \"annotators\": value[\"annotators\"],\n            \"gender_annotators\": value[\"gender_annotators\"],\n            \"age_annotators\": value[\"age_annotators\"],\n            \"ethnicities_annotators\": value[\"ethnicities_annotators\"],\n            \"study_levels_annotators\": value[\"study_levels_annotators\"],\n            \"countries_annotators\": value[\"countries_annotators\"],\n            \"labels_task1_1\": value[\"labels_task1_1\"],\n            \"labels_task1_2\": value[\"labels_task1_2\"],\n            \"labels_task1_3\": value[\"labels_task1_3\"]\n        }\n        augmented_count += 1\n\n# Merge original and augmented datasets\ndata.update(augmented_data)\n\n# Save Augmented Dataset\naugmented_file_path = \"EXIST2025_training_augmented_en.json\"\nwith open(augmented_file_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(data, f, ensure_ascii=False, indent=4)\n\nprint(f\"\\n✅ Data Augmentation Complete: {augmented_count} new samples added.\")\nprint(f\"Augmented dataset saved at: {augmented_file_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T00:16:32.555761Z","iopub.execute_input":"2025-03-27T00:16:32.556439Z","iopub.status.idle":"2025-03-27T00:16:35.747299Z","shell.execute_reply.started":"2025-03-27T00:16:32.556393Z","shell.execute_reply":"2025-03-27T00:16:35.746322Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"Applying EASE Augmentation: 100%|██████████| 6920/6920 [00:00<00:00, 13226.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n✅ Data Augmentation Complete: 13063 new samples added.\nAugmented dataset saved at: EXIST2025_training_augmented_en.json\n","output_type":"stream"}],"execution_count":4}]}