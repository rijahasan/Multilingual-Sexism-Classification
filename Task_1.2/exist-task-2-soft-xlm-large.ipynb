{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11769919,"sourceType":"datasetVersion","datasetId":7203709}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets evaluate accelerate sentencepiece","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T18:12:53.210301Z","iopub.status.idle":"2025-05-11T18:12:53.210699Z","shell.execute_reply.started":"2025-05-11T18:12:53.210497Z","shell.execute_reply":"2025-05-11T18:12:53.210524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport pandas as pd\nimport numpy as np\nimport datasets\nfrom tabulate import tabulate\nimport nltk\nfrom datetime import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T18:12:53.212116Z","iopub.status.idle":"2025-05-11T18:12:53.212446Z","shell.execute_reply.started":"2025-05-11T18:12:53.212291Z","shell.execute_reply":"2025-05-11T18:12:53.212305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ! pip install datasets\n# ! pip install sentencepiece\n# ! pip install rouge_score\n! pip install wandb\nimport wandb\n# wandb login}\nwandb.login(key=\"6930a5bf7436e98e8f1d44766c7b999ee9621ba9\")\n# wandb.init(project=\"LLM\", entity=\"sa07424-habib-university\", settings=wandb.Settings(init_timeout=200))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T18:12:53.213637Z","iopub.status.idle":"2025-05-11T18:12:53.214013Z","shell.execute_reply.started":"2025-05-11T18:12:53.213831Z","shell.execute_reply":"2025-05-11T18:12:53.213849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset\nfrom collections import defaultdict\n\n# === AEDA helper ===\nPUNCTUATIONS = ['.', ',', '!', '?', ';', ':']\ndef aeda(sentence, num_insertions=3):\n    words = sentence.split()\n    if not words:\n        return sentence\n    new_words = words.copy()\n    for _ in range(num_insertions):\n        insert_pos = random.randint(0, len(new_words))\n        punct = random.choice(PUNCTUATIONS)\n        new_words.insert(insert_pos, punct)\n    return ' '.join(new_words)\n\n# === Load Data ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\nlabel_classes = [\"NO\", \"DIRECT\", \"REPORTED\", \"JUDGEMENTAL\"]\n\n# === Count Label Distribution ===\nlabel_counts = defaultdict(int)\nfor soft in gold_soft_dict.values():\n    max_label = max(soft, key=soft.get)\n    label_counts[max_label] += 1\n\n# === Identify underrepresented labels (you can tune this threshold) ===\navg_count = np.mean(list(label_counts.values()))\nunderrepresented_labels = [label for label, count in label_counts.items() if count < avg_count]\n\n# === Process Tweets & Augment Underrepresented Only ===\ndef process_data_with_soft_labels(data, augment=True, augment_n=2):\n    tweets, labels, ids = [], [], []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in label_classes]\n\n        # Original tweet\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n        # Determine primary label\n        main_label = max(soft_label_dict, key=soft_label_dict.get)\n\n        # Augment only if underrepresented\n        if augment and main_label in underrepresented_labels:\n            for i in range(augment_n):\n                augmented_tweet = aeda(tweet)\n                tweets.append(augmented_tweet)\n                labels.append(soft_label_vector)\n                ids.append(f\"{tweet_id}_aug{i+1}\")\n\n    return tweets, labels, ids\n\n# Process English and Spanish data\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\ntokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-large\")\n\n# === Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": label\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\nprint(f\"✅ English train set size: {len(train_dataset_en)} (with selective augmentation)\")\nprint(f\"✅ Spanish train set size: {len(train_dataset_es)} (with selective augmentation)\")\n\nCORRECT_LABELS = label_classes\nimport json\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\n\n# === Load Tweets ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\n\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\n\n# === Load gold_soft_train ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\n# Convert gold_soft to a dict for fast access\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\n\n# Define binary labels\nCORRECT_LABELS = label_classes\n\n# === Process Tweets with Corresponding Soft Labels ===\ndef process_data_with_soft_labels(data):\n    tweets = []\n    labels = []\n    ids = []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue  # Skip if soft label not found\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n\n        # Build binary soft label vector [YES_score, NO_score]\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in CORRECT_LABELS]\n\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n    return tweets, labels, ids\n\n# Process both English and Spanish tweets\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# === Custom Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": labels\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\n\n# === Train Model ===\ndef train_model(train_dataset, val_dataset, output_dir):\n\n\n    # model_en = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n# tokenizer_en = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n    # model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"cardiffnlp/twitter-xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n    model = AutoModelForSequenceClassification.from_pretrained(\n            \"FacebookAI/xlm-roberta-large\",\n            num_labels=len(CORRECT_LABELS),\n            problem_type=\"multi_label_classification\"\n        )\n\n    # model = BertForSequenceClassification.from_pretrained(\n    #     \"FacebookAI/xlm-roberta-large\",\n    #     num_labels=len(CORRECT_LABELS),\n    #     problem_type=\"multi_label_classification\"\n    # )\n\n    training_args = TrainingArguments(\n    output_dir=output_dir,\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_total_limit=1,\n)\n\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset\n    )\n\n    trainer.train()\n    return trainer\n\n# === Train English and Spanish models ===\ntrainer_en = train_model(train_dataset_en, val_dataset_en, output_dir=\"./results/en_mbert_xlmR_large_aeda\")\ntrainer_es = train_model(train_dataset_es, val_dataset_es, output_dir=\"./results/es_mbert_xlmR_large_aeda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T18:13:08.109641Z","iopub.execute_input":"2025-05-11T18:13:08.110637Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b40babbc06614bf7838b2dd14a951c0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d08425cdcbba44e2989853d9a9740356"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f07a1c85f62456b9811840d1b203d9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc1d12d6d78849a893d6f280af300d26"}},"metadata":{}},{"name":"stdout","text":"✅ English train set size: 9763 (with selective augmentation)\n✅ Spanish train set size: 9763 (with selective augmentation)\n","output_type":"stream"},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43ecc56947c2482ea289abc383b0af8c"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250511_181326-pceu82v5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sa07424-habib-university/huggingface/runs/pceu82v5' target=\"_blank\">./results/en_mbert_xlmR_large_aeda</a></strong> to <a href='https://wandb.ai/sa07424-habib-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sa07424-habib-university/huggingface' target=\"_blank\">https://wandb.ai/sa07424-habib-university/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sa07424-habib-university/huggingface/runs/pceu82v5' target=\"_blank\">https://wandb.ai/sa07424-habib-university/huggingface/runs/pceu82v5</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='26' max='1384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  26/1384 33:55 < 31:59:28, 0.01 it/s, Epoch 0.07/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"import json\n\n# Load the dev dataset\nwith open(\"/kaggle/input/existdatasets/EXIST2025_dev.json\", \"r\", encoding=\"utf-8\") as f:\n    dev_data = json.load(f)\n\n# Split into English & Spanish\nenglish_dev_tweets = []\nenglish_dev_ids = []\nspanish_dev_tweets = []\nspanish_dev_ids = []\n\nfor entry in dev_data.values():\n    tweet_id = entry[\"id_EXIST\"]\n    tweet = entry[\"tweet\"]\n    lang = entry[\"lang\"]\n\n    if lang == \"en\":\n        english_dev_tweets.append(tweet)\n        english_dev_ids.append(tweet_id)\n    elif lang == \"es\":\n        spanish_dev_tweets.append(tweet)\n        spanish_dev_ids.append(tweet_id)\n\n# Debugging: Check split sizes\nprint(f\"English Dev Samples: {len(english_dev_tweets)}\")\nprint(f\"Spanish Dev Samples: {len(spanish_dev_tweets)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom transformers import BertForSequenceClassification, AutoModelForSequenceClassification, AutoTokenizer\n\n# Function to get the latest checkpoint\ndef get_latest_checkpoint(directory=\"./results\"):\n    checkpoints = [d for d in os.listdir(directory) if d.startswith(\"checkpoint-\")]\n    if not checkpoints:\n        raise ValueError(f\"No checkpoints found in {directory}\")\n    latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))[-1]\n    return os.path.join(directory, latest_checkpoint)\n\n# Load the best model checkpoint for English and Spanish\nlatest_checkpoint_en = get_latest_checkpoint(\"./results/en_mbert_xlmR_large_aeda\")\nlatest_checkpoint_es = get_latest_checkpoint(\"./results/es_mbert_xlmR_large_aeda\")\n\nprint(f\"Using latest checkpoint for English: {latest_checkpoint_en}\")\nprint(f\"Using latest checkpoint for Spanish: {latest_checkpoint_es}\")\n\nmodel_en = AutoModelForSequenceClassification.from_pretrained(latest_checkpoint_en)\nmodel_es = AutoModelForSequenceClassification.from_pretrained(latest_checkpoint_es)\ntokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-large\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## HARD Predictions","metadata":{}},{"cell_type":"code","source":"def predict_hard_labels_from_soft_model(tweets, ids, model, tokenizer, label_classes, output_file):\n    \"\"\"\n    Uses the soft model to predict a single hard label: \"YES\" or \"NO\".\n    - Assigns the label with the higher probability.\n    \"\"\"\n    # model.eval()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")#faster on gpu\n    model.to(device)\n\n    results = []\n\n    for tweet, tweet_id in zip(tweets, ids):\n        # encoding = tokenizer(text=tweet, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n        \n        encoding = tokenizer(tweet, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n        encoding = {key: val.to(device) for key, val in encoding.items()}\n        with torch.no_grad():\n            outputs = model(**encoding)\n\n        logits = outputs.logits.squeeze()\n        probs = torch.sigmoid(logits).cpu().numpy()\n\n        # Pick the label with the highest probability (YES or NO)\n        max_index = int(probs.argmax())\n        predicted_label = label_classes[max_index]\n\n        results.append({\n            \"test_case\": \"EXIST2025\",\n            \"id\": tweet_id,\n            \"value\": [predicted_label]  # Only one label\n        })\n    print(f\"Hard label predictions saved to {output_file}\")\n\npredict_hard_labels_from_soft_model(english_dev_tweets, english_dev_ids, model_en, tokenizer, label_classes, \"EXIST2025_dev_predictions_hard_xlmR_en.json\")\npredict_hard_labels_from_soft_model(spanish_dev_tweets, spanish_dev_ids, model_es, tokenizer, label_classes, \"EXIST2025_dev_predictions_hard_xlmR_es.json\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/working/EXIST2025_dev_predictions_hard_merged_es.json\", \"r\", encoding=\"utf-8\") as f:\n    es_data = json.load(f)\nwith open(\"/kaggle/working/EXIST2025_dev_predictions_hard_merged_en.json\", \"r\", encoding=\"utf-8\") as f:\n    en_data = json.load(f)\n\n# Assuming both files contain lists of predictions, merge them\nif isinstance(es_data, list) and isinstance(en_data, list):\n    merged_data = es_data + en_data\nelse:\n    raise ValueError(\"JSON structure is not a list. Ensure both files contain lists.\")\n\nimport json\n\npredictions = merged_data\n\nconverted = []\nfor entry in predictions:\n    # Convert the \"value\" list to a single string (first label only)\n    new_entry = {\n        \"test_case\": entry[\"test_case\"],\n        \"id\": entry[\"id\"],\n        \"value\": entry[\"value\"][0] if isinstance(entry[\"value\"], list) else entry[\"value\"]\n    }\n    converted.append(new_entry)\noutput_file = \"EXIST2025_dev_predictions_merged_hard_flat.json\"\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    json.dump(converted, f, indent=4)\n\nprint(f\"Predictions converted to gold format and saved to {output_file}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport json\nfrom tqdm import tqdm\n!pip install pyEvall\nfrom pyevall.evaluation import PyEvALLEvaluation\nfrom pyevall.utils.utils import PyEvALLUtils","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = \"/kaggle/working/EXIST2025_dev_predictions_merged_hard_flat.json\"         \ngold = \"/kaggle/input/existdatasets/EXIST2025_dev_task1_2_gold_hard.json\" \ntest = PyEvALLEvaluation() \nparams= dict() \nparams[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED  \nmetrics=[\"ICM\", \"ICMNorm\" ,\"FMeasure\"]                  # for hard        \nreport= test.evaluate(predictions, gold, metrics, **params) \nreport.print_report()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}