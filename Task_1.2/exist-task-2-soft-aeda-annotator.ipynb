{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11532581,"sourceType":"datasetVersion","datasetId":7232164}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets evaluate accelerate sentencepiece","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:35:07.596866Z","iopub.execute_input":"2025-05-11T17:35:07.597817Z","iopub.status.idle":"2025-05-11T17:36:17.323365Z","shell.execute_reply.started":"2025-05-11T17:35:07.597788Z","shell.execute_reply":"2025-05-11T17:36:17.322478Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport pandas as pd\nimport numpy as np\nimport datasets\nfrom tabulate import tabulate\nimport nltk\nfrom datetime import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:36:17.325266Z","iopub.execute_input":"2025-05-11T17:36:17.325539Z","iopub.status.idle":"2025-05-11T17:36:17.330864Z","shell.execute_reply.started":"2025-05-11T17:36:17.325516Z","shell.execute_reply":"2025-05-11T17:36:17.330201Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\n# ! pip install datasets\n# ! pip install sentencepiece\n# ! pip install rouge_score\n! pip install wandb\nimport wandb\n# wandb login}\nwandb.login(key=\"6930a5bf7436e98e8f1d44766c7b999ee9621ba9\")\n# wandb.init(project=\"LLM\", entity=\"sa07424-habib-university\", settings=wandb.Settings(init_timeout=200))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:36:17.331883Z","iopub.execute_input":"2025-05-11T17:36:17.332115Z","iopub.status.idle":"2025-05-11T17:36:29.648006Z","shell.execute_reply.started":"2025-05-11T17:36:17.332098Z","shell.execute_reply":"2025-05-11T17:36:29.647287Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msa07424\u001b[0m (\u001b[33msa07424-habib-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"label_classes = ['NO', 'DIRECT','REPORTED','JUDGEMENTAL']\nlabel2id = {'NO': 0, 'DIRECT': 1, 'REPORTED': 2, 'JUDGEMENTAL': 3}\nid2label  = {v: k for k, v in class2id.items()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Gold set ignores \"UNKNOWN\"","metadata":{"execution":{"iopub.status.busy":"2025-04-23T07:07:08.948082Z","iopub.execute_input":"2025-04-23T07:07:08.948389Z","iopub.status.idle":"2025-04-23T07:07:08.956910Z","shell.execute_reply.started":"2025-04-23T07:07:08.948367Z","shell.execute_reply":"2025-04-23T07:07:08.956085Z"}}},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T10:57:28.825473Z","iopub.execute_input":"2025-04-21T10:57:28.825697Z","iopub.status.idle":"2025-04-21T10:57:28.829684Z","shell.execute_reply.started":"2025-04-21T10:57:28.825678Z","shell.execute_reply":"2025-04-21T10:57:28.828929Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"class2id = {'NO': 0, 'DIRECT': 1, 'REPORTED': 2, 'JUDGEMENTAL': 3}\nid2class = {v: k for k, v in class2id.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T06:47:54.598691Z","iopub.execute_input":"2025-04-23T06:47:54.599061Z","iopub.status.idle":"2025-04-23T06:47:54.603079Z","shell.execute_reply.started":"2025-04-23T06:47:54.599031Z","shell.execute_reply":"2025-04-23T06:47:54.602228Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### Hyperparameter Tuning through randomized search","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding,\n)\nfrom datasets import Dataset\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport pandas as pd\n\n# Label mappings\nclass2id = {'NO': 0, 'DIRECT': 1, 'REPORTED': 2, 'JUDGEMENTAL': 3}\nid2class = {v: k for k, v in class2id.items()}\nimport random\nimport numpy as np\n\nrandom.seed(42)\nnp.random.seed(42)\n\n\n# Load and preprocess dataset\n# def load_and_prepare_dataset(csv_path):\n#     df = pd.read_csv(csv_path)\n#     df = df[['tweet', 'label']].rename(columns={'tweet': 'text'})\n#     df['label'] = df['label'].map(class2id)\n#     df = df.dropna().astype({'label': 'int'})\n#     df = df.sample(frac=1, random_state=42)  # Shuffle\n#     dataset = Dataset.from_pandas(df)\n#     train_test = dataset.train_test_split(test_size=0.1)\n#     return train_test['train'], train_test['test']\ndef load_and_prepare_dataset(csv_path):\n    df = pd.read_csv(csv_path)\n    df = df[['tweet', 'label']].rename(columns={'tweet': 'text'})\n    df = df.dropna().astype({'label': 'int'})  # Ensure labels are integers\n    df = df.sample(frac=1, random_state=42)  # Shuffle\n    dataset = Dataset.from_pandas(df)\n    train_test = dataset.train_test_split(test_size=0.1)\n    return train_test['train'], train_test['test']\n\n# Tokenization\ndef preprocess(train_data, val_data, tokenizer, max_length=256):\n    def tokenize_fn(example):\n        return tokenizer(example['text'], truncation=True, padding='max_length', max_length=max_length)\n    train_data = train_data.map(tokenize_fn, batched=True)\n    val_data = val_data.map(tokenize_fn, batched=True)\n    return train_data, val_data\n\n# Metrics computation\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = np.argmax(pred.predictions, axis=1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n    acc = accuracy_score(labels, preds)\n    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n\n# Hyperparameter search space\nparam_dist = {\n    \"learning_rate\": [1e-5, 3e-5, 5e-5],\n    \"per_device_train_batch_size\": [8, 16, 32, 64],\n    \"num_train_epochs\": [2, 3, 4],\n    \"weight_decay\": [0.0, 0.01, 0.1],\n    \"warmup_steps\": [100, 200, 500],\n}\n\ndef random_search(train_data, val_data, tokenizer, model, n_iter=25):\n    best_score = -1\n    best_params = None\n\n    for i in range(n_iter):\n        print(f\"Iter {i}\")\n        # Randomly sample hyperparameters\n        params = {\n            \"learning_rate\": random.choice(param_dist[\"learning_rate\"]),\n            \"per_device_train_batch_size\": random.choice(param_dist[\"per_device_train_batch_size\"]),\n            \"num_train_epochs\": 3,\n            # \"num_train_epochs\": random.choice(param_dist[\"num_train_epochs\"]),\n            \"weight_decay\": random.choice(param_dist[\"weight_decay\"]),\n            \"warmup_steps\": random.choice(param_dist[\"warmup_steps\"]),\n        }\n\n        # Training arguments with sampled params\n        training_args = TrainingArguments(\n            output_dir=\"./results\",\n            evaluation_strategy=\"epoch\",\n            save_strategy=\"epoch\",\n            logging_steps=50,\n            load_best_model_at_end=True,\n            **params\n        )\n\n        # Trainer\n        trainer = Trainer(\n            model=model,\n            args=training_args,\n            train_dataset=train_data,\n            eval_dataset=val_data,\n            tokenizer=tokenizer,\n            data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n            compute_metrics=compute_metrics,\n        )\n\n        # Train and evaluate\n        trainer.train()\n        eval_results = trainer.evaluate()\n\n        # Track best model\n        current_score = eval_results[\"eval_f1\"]\n        if current_score > best_score:\n            best_score = current_score\n            best_params = params\n\n    return best_params, best_score\n\ndef train_model(csv_path, model_checkpoint, save_name, n_iter=25):\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4, )\n\n    train_data, val_data = load_and_prepare_dataset(csv_path)\n    train_data, val_data = preprocess(train_data, val_data, tokenizer)\n\n    # Perform random search\n    best_params, best_score = random_search(train_data, val_data, tokenizer, model, n_iter=n_iter)\n    print(f\"Best Hyperparameters: {best_params}\")\n    print(f\"Best F1 Score: {best_score:.4f}\")\n\n    # Train final model with best params\n    training_args = TrainingArguments(\n        output_dir=\"./results\",\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        logging_steps=50,\n        load_best_model_at_end=True,\n        **best_params\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_data,\n        eval_dataset=val_data,\n        tokenizer=tokenizer,\n        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n    trainer.save_model(f\"{save_name}_best_model\")\n\n# Run training with hyperparameter tuning\ntrain_model(\"/kaggle/input/existdatasets/trainin_gold_labels_en.csv\", \"distilroberta-base\", \"distilroberta-base\", n_iter=25)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* #### For English\nBest Hyperparameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.1, 'warmup_steps': 200}\n#### Best F1 Score: 0.5134\n\nBest Hyperparameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.0, 'warmup_steps': 500}\n#### Best F1 Score: 0.5676\n\n#### For Spanish\nBest Hyperparameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.1, 'warmup_steps': 200}\n#### Best F1 Score: 0.5181","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding\nfrom datasets import Dataset\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n\nimport pandas as pd\nimport numpy as np\n\ndef load_and_prepare_dataset(csv_path):\n    df = pd.read_csv(csv_path)\n    df = df[['tweet', 'label']].rename(columns={'tweet': 'text'})\n    df = df.dropna().astype({'label': 'int'})  # Ensure labels are integers\n    df = df.sample(frac=1, random_state=42)  # Shuffle\n    dataset = Dataset.from_pandas(df)\n    train_test = dataset.train_test_split(test_size=0.1)\n    return train_test['train'], train_test['test']\n\n\ndef preprocess(train_data, val_data, tokenizer, max_length=256):\n    def tokenize_fn(example):\n        return tokenizer(example['text'], truncation=True, padding='max_length', max_length=max_length)\n    train_data = train_data.map(tokenize_fn, batched=True)\n    val_data = val_data.map(tokenize_fn, batched=True)\n    return train_data, val_data\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = np.argmax(pred.predictions, axis=1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n\ndef train_model(json_path, model_checkpoint, save_name):\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4)\n\n    train_data, val_data = load_and_prepare_dataset(json_path)\n    train_data, val_data = preprocess(train_data, val_data, tokenizer)\n\n    training_args = TrainingArguments(\n        output_dir=\"results\",\n        num_train_epochs=4,\n        # learning_rate=5e-5,\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=16,\n        # warmup_steps=500,\n        # weight_decay=0.0,\n        logging_dir=\"logs\",\n        logging_steps=50,\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n    )\n\n    # data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_data,\n        eval_dataset=val_data,\n        tokenizer=tokenizer,\n        # data_collator=data_collator,\n        compute_metrics=compute_metrics\n    )\n    trainer.train()\n    metrics = trainer.evaluate()\n    # print(metrics)\n    print(\"Evaluation Results:\")\n    for k, v in metrics.items():\n        print(f\"{k}: {v:.4f}\")\n    \n# Best Hyperparameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.1, 'warmup_steps': 200}\n\n    save_path = f\"{save_name}_mergedlang_es\"\n    model.save_pretrained(save_path)\n    tokenizer.save_pretrained(save_path)\n    print(f\"Model saved to {save_path}\")\n    return model,tokenizer\n\nmodel,tokenizer = train_model(\"/kaggle/input/existdatasets/trainin_gold_labels_es.csv\", \"FacebookAI/xlm-roberta-base\", \"FacebookAI/xlm-roberta-base\")","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\ntokenizer.save_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:25:14.172047Z","iopub.execute_input":"2025-04-23T07:25:14.172397Z","iopub.status.idle":"2025-04-23T07:25:15.275796Z","shell.execute_reply.started":"2025-04-23T07:25:14.172373Z","shell.execute_reply":"2025-04-23T07:25:15.275084Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/distilroberta-base_mergedlang_en/tokenizer_config.json',\n '/kaggle/working/distilroberta-base_mergedlang_en/special_tokens_map.json',\n '/kaggle/working/distilroberta-base_mergedlang_en/vocab.json',\n '/kaggle/working/distilroberta-base_mergedlang_en/merges.txt',\n '/kaggle/working/distilroberta-base_mergedlang_en/added_tokens.json',\n '/kaggle/working/distilroberta-base_mergedlang_en/tokenizer.json')"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"def train_model(encodings, labels, num_labels, modelname):\n    \"\"\"Train a BERT model on the given encodings and labels.\"\"\"\n    # Split the data into training and validation sets\n    train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n        encodings['input_ids'], labels, test_size=0.2, random_state=42\n    )\n    train_masks, val_masks = train_test_split(\n        encodings['attention_mask'], test_size=0.2, random_state=42\n    )\n\n    train_encodings = {'input_ids': train_inputs, 'attention_mask': train_masks}\n    val_encodings = {'input_ids': val_inputs, 'attention_mask': val_masks}\n\n    # # Convert labels to tensors\n    # train_labels = torch.tensor(train_labels)\n    # val_labels = torch.tensor(val_labels)\n\n    train_dataset = CustomDataset(train_encodings, train_labels)\n    val_dataset = CustomDataset(val_encodings, val_labels)\n\n    # if 'bert-' in modelname:\n    #     model = BertForSequenceClassification.from_pretrained(modelname,num_labels=4,problem_type=\"multi_label_classification\")    \n    # elif 'distilbert' in modelname:\n    #     model = DistilBertTokenizer.from_pretrained(model)\n    # else:\n    model = AutoModelForSequenceClassification.from_pretrained(modelname, num_labels=4, id2label=id2label, label2id=label2id)\n    \n    training_args = TrainingArguments(\n        output_dir=\"./dismiss\",\n        learning_rate=2e-5,\n        eval_strategy=\"epoch\",\n        weight_decay=0.0048,\n        num_train_epochs=4,              #4 epochs were found to be optimal after which performance decreases\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=16,\n        save_steps=500,\n        save_strategy=\"epoch\", \n        save_total_limit=2,\n        logging_dir='./logs',  # optional: directory for logs\n        greater_is_better=False,      # Lower eval_loss is better\n        warmup_steps=500,             # Learning rate warmup\n        load_best_model_at_end=True,\n\n\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        processing_class=tokenizer,\n        compute_metrics=compute_metrics,\n   \n    )\n    # print(\"Model: \"+modelname+\"Mode: \"+)\n    trainer.train()\n    return trainer, model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T11:10:40.833528Z","iopub.execute_input":"2025-04-21T11:10:40.833891Z","iopub.status.idle":"2025-04-21T11:10:40.841756Z","shell.execute_reply.started":"2025-04-21T11:10:40.833863Z","shell.execute_reply":"2025-04-21T11:10:40.841006Z"}},"outputs":[],"execution_count":89},{"cell_type":"markdown","source":"### Base Training with Translated Augmented Data","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\n\n# === Load Tweets ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\n\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\n\n# === Load gold_soft_train ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\n# Convert gold_soft to a dict for fast access\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\n\nCORRECT_LABELS = label_classes\n\n# === Process Tweets with Corresponding Soft Labels ===\ndef process_data_with_soft_labels(data):\n    tweets = []\n    labels = []\n    ids = []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue  # Skip if soft label not found\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in CORRECT_LABELS]\n        tweet = entry[\"tweet\"]\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n    return tweets, labels, ids\n\n# Process both English and Spanish tweets\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# === Tokenizer ===\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\ntokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n\n# === Custom Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": labels\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\n# === Train Model ===\ndef train_model(train_dataset, val_dataset, output_dir):\n\n\n    # model_en = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n# tokenizer_en = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n    model = AutoModelForSequenceClassification.from_pretrained(\n            \"FacebookAI/xlm-roberta-base\",\n            num_labels=len(CORRECT_LABELS),\n            problem_type=\"multi_label_classification\"\n        )\n\n    # model = BertForSequenceClassification.from_pretrained(\n    #     \"FacebookAI/xlm-roberta-base\",\n    #     num_labels=len(CORRECT_LABELS),\n    #     problem_type=\"multi_label_classification\"\n    # )\n\n    training_args = TrainingArguments(\n    output_dir=output_dir,\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_total_limit=2\n)\n\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset\n    )\n\n    trainer.train()\n    return trainer\n\n# === Train English and Spanish models ===\ntrainer_en = train_model(train_dataset_en, val_dataset_en, output_dir=\"./results/en_xlm_roberta\")\n# trainer_es = train_model(train_dataset_es, val_dataset_es, output_dir=\"./results/es\")","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer_es.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:04:21.644905Z","iopub.execute_input":"2025-04-23T14:04:21.645235Z","iopub.status.idle":"2025-04-23T14:04:35.828951Z","shell.execute_reply.started":"2025-04-23T14:04:21.645211Z","shell.execute_reply":"2025-04-23T14:04:35.828262Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [44/44 00:13]\n    </div>\n    "},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.4226243197917938,\n 'eval_runtime': 14.1753,\n 'eval_samples_per_second': 97.635,\n 'eval_steps_per_second': 3.104,\n 'epoch': 4.0}"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, f1_score\nimport torch\nfrom transformers import EvalPrediction\n\ndef compute_metrics(eval_pred: EvalPrediction):\n    logits, labels = eval_pred\n    logits = torch.tensor(logits)  # Convert logits to a PyTorch tensor\n    preds = torch.argmax(logits, dim=1).numpy()  # Get the predicted class indices\n    \n    # No need to call .numpy() on labels, as it is already a NumPy array\n    labels = labels  # labels are already a NumPy array\n\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds, average='weighted')\n    f1 = f1_score(labels, preds, average='weighted')\n\n    return {'accuracy': accuracy, 'precision': precision, 'f1': f1}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T11:10:44.522723Z","iopub.execute_input":"2025-04-21T11:10:44.523043Z","iopub.status.idle":"2025-04-21T11:10:44.529341Z","shell.execute_reply.started":"2025-04-21T11:10:44.523014Z","shell.execute_reply":"2025-04-21T11:10:44.528390Z"}},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"### Models Tried\n##### Best ones: FacebookAI/xlm-roberta-base, FacebookAI/xlm-roberta-large, distilroberta-base, cardiffnlp/twitter-xlm-roberta-base\n","metadata":{}},{"cell_type":"code","source":"# PlanTL-GOB-ES/RoBERTalex\n# FacebookAI/xlm-roberta-base\n# distilbert/distilbert-base-uncased\n# google-bert/bert-base-multilingual-uncased\n# JonatanGk/roberta-base-bne-finetuned-hate-speech-offensive-spanish\n# distilroberta-base\nmodelname = \"distilroberta-base\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T11:10:50.031354Z","iopub.execute_input":"2025-04-21T11:10:50.031709Z","iopub.status.idle":"2025-04-21T11:10:50.036276Z","shell.execute_reply.started":"2025-04-21T11:10:50.031679Z","shell.execute_reply":"2025-04-21T11:10:50.035241Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"encodings, labels, tokenizer = initializetokenizer(modelname, \"en\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T11:10:50.432694Z","iopub.execute_input":"2025-04-21T11:10:50.432935Z","iopub.status.idle":"2025-04-21T11:10:51.147711Z","shell.execute_reply.started":"2025-04-21T11:10:50.432915Z","shell.execute_reply":"2025-04-21T11:10:51.146987Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"trainer,model = train_model(encodings, labels, 4, modelname)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# models = [\"PlanTL-GOB-ES/RoBERTalex\",\n# \"FacebookAI/xlm-roberta-base\",\n# \"distilbert/distilbert-base-uncased\",\n# \"google-bert/bert-base-multilingual-uncased\",\n# \"JonatanGk/roberta-base-bne-finetuned-hate-speech-offensive-spanish\",\n# \"FacebookAI/xlm-roberta-base\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:51:19.672879Z","iopub.execute_input":"2025-04-20T23:51:19.673208Z","iopub.status.idle":"2025-04-20T23:51:19.677248Z","shell.execute_reply.started":"2025-04-20T23:51:19.673182Z","shell.execute_reply":"2025-04-20T23:51:19.676459Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/bert-base-multilingual-cased_en_backtrans\")\ntokenizer.save_pretrained(\"/kaggle/working/bert-base-multilingual-cased_en_backtrans\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:51:19.678798Z","iopub.execute_input":"2025-04-20T23:51:19.679088Z","iopub.status.idle":"2025-04-20T23:51:21.188151Z","shell.execute_reply.started":"2025-04-20T23:51:19.679066Z","shell.execute_reply":"2025-04-20T23:51:21.187475Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/bert-base-multilingual-cased_en_backtrans/tokenizer_config.json',\n '/kaggle/working/bert-base-multilingual-cased_en_backtrans/special_tokens_map.json',\n '/kaggle/working/bert-base-multilingual-cased_en_backtrans/vocab.txt',\n '/kaggle/working/bert-base-multilingual-cased_en_backtrans/added_tokens.json',\n '/kaggle/working/bert-base-multilingual-cased_en_backtrans/tokenizer.json')"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"trainedmodels=[]\nfor modelname in models:\n    model = \"model\"+modelname+\"_en_backtrans\"\n    encodings, labels, tokenizer = initializetokenizer(modelname, \"en\")\n    trainer,model = train_model(encodings, labels, 4, modelname)\n    trainedmodels.append([trainer,model])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for modelname in range(len(models)):\n    trained[model][0].save_pretrained(\"/kaggle/working/\"+models[modelname]+\"_en_backtrans\")\n    trained[model][1].save_pretrained(\"/kaggle/working/\"+models[modelname]+\"_en_backtrans\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:46:54.716222Z","iopub.status.idle":"2025-04-21T00:46:54.716507Z","shell.execute_reply":"2025-04-21T00:46:54.716391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for modelname in range(len(models)):\n    trained[model]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/xlmroberta_es_aug\")\ntokenizer.save_pretrained(\"/kaggle/working/xlmroberta_es_aug\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T17:21:05.586737Z","iopub.execute_input":"2025-03-29T17:21:05.587104Z","iopub.status.idle":"2025-03-29T17:21:08.549459Z","shell.execute_reply.started":"2025-03-29T17:21:05.587078Z","shell.execute_reply":"2025-03-29T17:21:08.548635Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/xlmroberta_es_aug/tokenizer_config.json',\n '/kaggle/working/xlmroberta_es_aug/special_tokens_map.json',\n '/kaggle/working/xlmroberta_es_aug/sentencepiece.bpe.model',\n '/kaggle/working/xlmroberta_es_aug/added_tokens.json',\n '/kaggle/working/xlmroberta_es_aug/tokenizer.json')"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"import torch\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n\ndef classify_text_with_model(tokenizer, text, model):\n    \"\"\"\n    Classify the input text using the given model and tokenizer.\n    Assumes multi-class classification task.\n    \"\"\"\n    # Automatically detect available device (GPU if available, otherwise CPU)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Automatically choose GPU if available\n    \n    # Move model to the correct device\n    model.to(device)\n\n    # Tokenize the input text\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n    # Move the inputs to the same device as the model\n    inputs = {key: val.to(device) for key, val in inputs.items()}\n\n    # Set the model to evaluation mode\n    model.eval()\n\n    # Perform inference\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Get the predicted class (highest logit)\n    logits = outputs.logits\n    predicted_class = torch.argmax(logits, dim=1).item()  # Get the index of the predicted class\n\n    return predicted_class\n\n# Example usage:\n# Assuming the model and tokenizer are loaded\nmodel = DistilBertForSequenceClassification.from_pretrained('./english_model')\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\ntext = \"I dont support women who judge women\"\npredicted_class = classify_text_with_model(tokenizer, text, model)\nprint(f\"Predicted class: {id2label[predicted_class]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:40:55.219465Z","iopub.execute_input":"2025-03-27T04:40:55.219837Z","iopub.status.idle":"2025-03-27T04:40:55.245767Z","shell.execute_reply.started":"2025-03-27T04:40:55.219806Z","shell.execute_reply":"2025-03-27T04:40:55.244721Z"}},"outputs":[{"name":"stdout","text":"Predicted class: REPORTED\n","output_type":"stream"}],"execution_count":61},{"cell_type":"markdown","source":"### Preprocessing","metadata":{}},{"cell_type":"code","source":"import json\nimport re\n\ndef clean_and_save_tweets(input_path, output_path):\n    def clean(text):\n            # text = re.sub(r'https?://\\S+', '[URL]', text)   # Replace URL with token\n            text = re.sub(r'\\s+', ' ', text).strip()        # Normalize spaces\n            return text\n\n    with open(input_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n\n    for entry in data.values():\n        if 'tweet' in entry:\n            entry['tweet'] = clean(entry['tweet'])\n\n    with open(output_path, 'w', encoding='utf-8') as f:\n        json.dump(data, f, indent=2, ensure_ascii=False)\n\n# Example usage\nclean_and_save_tweets(\n    '/kaggle/input/existdatasets/EXIST2025_training_translated_en.json',\n    'EXIST2025_training_translated_en_cleaned.json'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:33:35.035029Z","iopub.execute_input":"2025-04-24T08:33:35.035685Z","iopub.status.idle":"2025-04-24T08:33:36.019963Z","shell.execute_reply.started":"2025-04-24T08:33:35.035653Z","shell.execute_reply":"2025-04-24T08:33:36.019247Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## With Annotator Data","metadata":{}},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:34:06.925198Z","iopub.status.idle":"2025-05-11T17:34:06.925609Z","shell.execute_reply.started":"2025-05-11T17:34:06.925417Z","shell.execute_reply":"2025-05-11T17:34:06.925435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport pandas as pd\nimport numpy as np\nimport datasets\nfrom tabulate import tabulate\nimport nltk\nfrom datetime import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:34:30.350022Z","iopub.execute_input":"2025-05-11T17:34:30.350273Z","iopub.status.idle":"2025-05-11T17:34:56.604947Z","shell.execute_reply.started":"2025-05-11T17:34:30.350251Z","shell.execute_reply":"2025-05-11T17:34:56.604189Z"}},"outputs":[{"name":"stderr","text":"2025-05-11 17:34:42.688565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746984882.875198      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746984882.926624      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Attempt 1","metadata":{}},{"cell_type":"code","source":"import json\nimport numpy as np\nfrom collections import defaultdict\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\n\n# === Helper function to split dataset by annotator ===\ndef split_data_by_annotator(data):\n    split_data = defaultdict(list)  # dictionary to hold data for each annotator\n\n    # Iterate through each entry in the dataset\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        # Collect metadata for each annotator\n        for i in range(6):  # Assuming there are 6 annotators\n            annotator_key = f\"Annotator_{i+1}\"\n            annotator_metadata = {\n                \"gender\": entry[\"gender_annotators\"][i],\n                \"age\": entry[\"age_annotators\"][i],\n                \"ethnicity\": entry[\"ethnicities_annotators\"][i],\n                \"study_level\": entry[\"study_levels_annotators\"][i],\n                \"country\": entry[\"countries_annotators\"][i]\n            }\n\n            # For each annotator, create a separate dataset with metadata\n            split_data[annotator_key].append({\n                \"id_EXIST\": tweet_id,\n                \"tweet\": tweet,\n                \"metadata\": annotator_metadata,\n                \"labels_task1_1\": entry[\"labels_task1_1\"][i],\n                \"labels_task1_2\": entry[\"labels_task1_2\"][i],\n                \"labels_task1_3\": entry[\"labels_task1_3\"][i]\n            })\n\n    return split_data\n\n# === Define a custom Dataset class ===\nclass TweetDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length=256):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data[idx]['tweet']\n        labels = [self.data[idx]['labels_task1_2']]  # Use labels from task 1.2 only\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'labels': torch.tensor(labels, dtype=torch.long)\n        }\n\n# === Fine-tune the Component Model for each annotator ===\ndef fine_tune_component_model(train_data, model_name=\"cardiffnlp/twitter-xlm-roberta-base\", num_labels=3):\n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n    \n    # Prepare dataset for training\n    train_dataset = TweetDataset(train_data, tokenizer)\n    \n    training_args = TrainingArguments(\n        output_dir=\"./results\",  \n        num_train_epochs=4,\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=16,\n        logging_dir=\"./logs\",\n        logging_steps=100,\n    )\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset\n    )\n    \n    trainer.train()\n    return model\n\n# === Get soft and hard labels from predictions ===\ndef get_soft_labels(predictions):\n    # Soft label: Compute the probability distribution for each class\n    soft_labels = np.mean(predictions, axis=0)  # Average the predicted probabilities\n    soft_labels /= np.sum(soft_labels)  # Ensure the sum is 1\n    return soft_labels\n\ndef get_hard_labels(predictions, threshold=2):\n    # Hard label: Majority vote based on predictions\n    hard_labels = np.array([1 if np.sum(pred == 1) > threshold else 0 for pred in zip(*predictions)])\n    return hard_labels\n\n# === Main code ===\ndef train_and_process_language_data(data, language, tokenizer, model_name=\"cardiffnlp/twitter-xlm-roberta-base\"):\n    # 1. Split the dataset by annotator\n    split_data = split_data_by_annotator(data)\n\n    # 2. Fine-tune models for each annotator\n    component_models = []\n    for annotator_key, train_data in split_data.items():\n        model = fine_tune_component_model(train_data, model_name)\n        component_models.append(model)\n\n    # 3. Collect predictions from all models\n    predictions = []\n    for model in component_models:\n        # Assuming each model outputs probabilities for each class\n        pred = model.predict(val_dataset)  # Modify as per your model prediction logic\n        predictions.append(pred)\n\n    # 4. Calculate soft labels (probability distribution)\n    soft_labels = get_soft_labels(predictions)\n\n    # 5. Calculate hard labels (majority voting)\n    hard_labels = get_hard_labels(predictions)\n\n    # 6. Save results in required submission format\n    def save_results(soft_labels, hard_labels, output_file):\n        results = {\n            \"soft_labels\": soft_labels,\n            \"hard_labels\": hard_labels\n        }\n        with open(output_file, \"w\") as f:\n            json.dump(results, f)\n\n    save_results(soft_labels, hard_labels, f\"final_output_{language}.json\")\n\n\n# === Load and train for English ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\n\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\ntrain_and_process_language_data(data_en, \"en\", tokenizer)\n\n# === Load and train for Spanish ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\n\ntrain_and_process_language_data(data_es, \"es\", tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T07:56:15.621888Z","iopub.execute_input":"2025-04-24T07:56:15.622174Z","iopub.status.idle":"2025-04-24T08:19:27.791593Z","shell.execute_reply.started":"2025-04-24T07:56:15.622152Z","shell.execute_reply":"2025-04-24T08:19:27.790787Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/652 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"150aa16ac41e4cff807de51f071f5df1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3467a5565b048048bed9981b9fef8a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87cd1dd0062c4d2a8645100de0371b37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dbbcbde34b34fd1b99708a990cf4a16"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36992448896448b9af850d5c9eb406fb"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250424_075627-lq6wkkyp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sa07424-habib-university/huggingface/runs/lq6wkkyp' target=\"_blank\">./results/en_xlm_twt_roberta_w_preprocessing</a></strong> to <a href='https://wandb.ai/sa07424-habib-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sa07424-habib-university/huggingface' target=\"_blank\">https://wandb.ai/sa07424-habib-university/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sa07424-habib-university/huggingface/runs/lq6wkkyp' target=\"_blank\">https://wandb.ai/sa07424-habib-university/huggingface/runs/lq6wkkyp</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='692' max='692' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [692/692 11:13, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.464400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.421200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.407200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.392600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.386000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.368000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSome weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='692' max='692' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [692/692 11:33, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.461300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.421500</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.400500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.386500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.378400</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.359700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"#### Attempt 2","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\nfrom collections import defaultdict\n\n# === Load Data ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\nlabel_classes = [\"NO\", \"DIRECT\", \"REPORTED\", \"JUDGEMENTAL\"]\n\n# === Count Label Distribution ===\nlabel_counts = defaultdict(int)\nfor soft in gold_soft_dict.values():\n    max_label = max(soft, key=soft.get)\n    label_counts[max_label] += 1\n\n# === Identify underrepresented labels (you can tune this threshold) ===\navg_count = np.mean(list(label_counts.values()))\nunderrepresented_labels = [label for label, count in label_counts.items() if count < avg_count]\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:39:35.318898Z","iopub.execute_input":"2025-05-11T17:39:35.319615Z","iopub.status.idle":"2025-05-11T17:39:41.214909Z","shell.execute_reply.started":"2025-05-11T17:39:35.319588Z","shell.execute_reply":"2025-05-11T17:39:41.214333Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/652 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee1613b78ee746f69bb072a719c3402d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d23a2a8e20724651afa84114a09d38ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1659fe458c3c4af8a39765897bac728c"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# === AEDA helper ===\nPUNCTUATIONS = ['.', ',', '!', '?', ';', ':']\ndef aeda(sentence, num_insertions=3):\n    words = sentence.split()\n    if not words:\n        return sentence\n    new_words = words.copy()\n    for _ in range(num_insertions):\n        insert_pos = random.randint(0, len(new_words))\n        punct = random.choice(PUNCTUATIONS)\n        new_words.insert(insert_pos, punct)\n    return ' '.join(new_words)\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256, is_soft=True):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.is_soft = is_soft\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.float if self.is_soft else torch.long)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": label\n        }\ndef process_data_with_soft_labels(data, gold_soft_dict, label_classes, augment=True, augment_n=2):\n    tweets, labels, ids = [], [], []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in label_classes]\n\n        # Original tweet\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n        # Determine primary label\n        main_label = max(soft_label_dict, key=soft_label_dict.get)\n\n        # Augment only if underrepresented\n        if augment and main_label in underrepresented_labels:\n            for i in range(augment_n):\n                augmented_tweet = aeda(tweet)\n                tweets.append(augmented_tweet)\n                labels.append(soft_label_vector)\n                ids.append(f\"{tweet_id}_aug{i+1}\")\n\n    return tweets, labels, ids\ndef process_data_with_hard_labels(data, gold_soft_dict, label_classes):\n    tweets, labels, ids = [], [], []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n        hard_label = max(soft_label_dict, key=soft_label_dict.get)\n        hard_label_vector = [1 if label == hard_label else 0 for label in label_classes]\n\n        # Collect original tweet and label\n        tweets.append(tweet)\n        labels.append(hard_label_vector)\n        ids.append(tweet_id)\n\n    return tweets, labels, ids\n\ndef get_datasets(tweets, labels, ids, tokenizer, is_soft=True):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer, is_soft=is_soft)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer, is_soft=is_soft)\n    return train_dataset, val_dataset\ndef train_model(train_dataset, val_dataset, output_dir, model_name=\"cardiffnlp/twitter-xlm-roberta-base\", num_labels=4):\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=num_labels,\n        problem_type=\"multi_label_classification\"\n    )\n\n    training_args = TrainingArguments(\n        output_dir=output_dir,\n        do_train=True,\n        do_eval=True,\n        num_train_epochs=4,\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=16,\n        logging_dir=\"./logs\",\n        logging_steps=100,\n        save_total_limit=1,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset\n    )\n\n    trainer.train()\n    return trainer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:44:18.120201Z","iopub.execute_input":"2025-05-11T17:44:18.120742Z","iopub.status.idle":"2025-05-11T17:44:18.135936Z","shell.execute_reply.started":"2025-05-11T17:44:18.120721Z","shell.execute_reply":"2025-05-11T17:44:18.135149Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Process and train for soft labels\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en, gold_soft_dict, label_classes)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es, gold_soft_dict, label_classes)\n\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en, tokenizer, is_soft=True)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es, tokenizer, is_soft=True)\n\ntrainer_en = train_model(train_dataset_en, val_dataset_en, output_dir=\"./results/en_xlm_roberta_soft\")\ntrainer_es = train_model(train_dataset_es, val_dataset_es, output_dir=\"./results/es_xlm_roberta_soft\")\n\n# Process and train for hard labels\n# tweets_en_hard, labels_en_hard, ids_en_hard = process_data_with_hard_labels(data_en, gold_soft_dict, label_classes)\n# tweets_es_hard, labels_es_hard, ids_es_hard = process_data_with_hard_labels(data_es, gold_soft_dict, label_classes)\n\n# train_dataset_en_hard, val_dataset_en_hard = get_datasets(tweets_en_hard, labels_en_hard, ids_en_hard, tokenizer, is_soft=False)\n# train_dataset_es_hard, val_dataset_es_hard = get_datasets(tweets_es_hard, labels_es_hard, ids_es_hard, tokenizer, is_soft=False)\n\n# trainer_en_hard = train_model(train_dataset_en_hard, val_dataset_en_hard, output_dir=\"./results/en_xlm_roberta_hard\")\n# trainer_es_hard = train_model(train_dataset_es_hard, val_dataset_es_hard, output_dir=\"./results/es_xlm_roberta_hard\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:44:22.561291Z","iopub.execute_input":"2025-05-11T17:44:22.561829Z","iopub.status.idle":"2025-05-11T18:28:22.313806Z","shell.execute_reply.started":"2025-05-11T17:44:22.561806Z","shell.execute_reply":"2025-05-11T18:28:22.313059Z"}},"outputs":[{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1224' max='1224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1224/1224 21:54, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.491500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.462700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.442900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.429200</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.419300</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.410900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.394300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.389800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.391100</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.375900</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.375000</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.374500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSome weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1224' max='1224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1224/1224 21:56, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.503200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.469300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.450500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.436800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.425100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.416700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.394300</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.395900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.378800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.378500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.378400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### Testing Annotator","metadata":{}},{"cell_type":"code","source":"import json\n\n# Load the dev dataset\nwith open(\"/kaggle/input/existdatasets/EXIST2025_dev.json\", \"r\", encoding=\"utf-8\") as f:\n    dev_data = json.load(f)\n\n# Split into English & Spanish\nenglish_dev_tweets = []\nenglish_dev_ids = []\nspanish_dev_tweets = []\nspanish_dev_ids = []\n\nfor entry in dev_data.values():\n    tweet_id = entry[\"id_EXIST\"]\n    tweet = entry[\"tweet\"]\n    lang = entry[\"lang\"]\n\n    if lang == \"en\":\n        english_dev_tweets.append(tweet)\n        english_dev_ids.append(tweet_id)\n    elif lang == \"es\":\n        spanish_dev_tweets.append(tweet)\n        spanish_dev_ids.append(tweet_id)\n\n# Debugging: Check split sizes\nprint(f\"English Dev Samples: {len(english_dev_tweets)}\")\nprint(f\"Spanish Dev Samples: {len(spanish_dev_tweets)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T18:43:18.117419Z","iopub.execute_input":"2025-05-11T18:43:18.117705Z","iopub.status.idle":"2025-05-11T18:43:18.160756Z","shell.execute_reply.started":"2025-05-11T18:43:18.117686Z","shell.execute_reply":"2025-05-11T18:43:18.160117Z"}},"outputs":[{"name":"stdout","text":"English Dev Samples: 489\nSpanish Dev Samples: 549\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import os\nfrom transformers import BertForSequenceClassification, AutoModelForSequenceClassification, AutoTokenizer\n\n# Function to get the latest checkpoint\ndef get_latest_checkpoint(directory=\"./results\"):\n    checkpoints = [d for d in os.listdir(directory) if d.startswith(\"checkpoint-\")]\n    if not checkpoints:\n        raise ValueError(f\"No checkpoints found in {directory}\")\n    latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))[-1]\n    return os.path.join(directory, latest_checkpoint)\n\n# Load the best model checkpoint for English and Spanish\nlatest_checkpoint_en = get_latest_checkpoint(\"./results/en_xlm_roberta_soft\")\nlatest_checkpoint_es = get_latest_checkpoint(\"./results/es_xlm_roberta_soft\")\n\nprint(f\"Using latest checkpoint for English: {latest_checkpoint_en}\")\nprint(f\"Using latest checkpoint for Spanish: {latest_checkpoint_es}\")\n\nmodel_en = AutoModelForSequenceClassification.from_pretrained(latest_checkpoint_en)\nmodel_es = AutoModelForSequenceClassification.from_pretrained(latest_checkpoint_es)\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T18:43:18.490510Z","iopub.execute_input":"2025-05-11T18:43:18.490781Z","iopub.status.idle":"2025-05-11T18:43:21.139642Z","shell.execute_reply.started":"2025-05-11T18:43:18.490762Z","shell.execute_reply":"2025-05-11T18:43:21.139016Z"}},"outputs":[{"name":"stdout","text":"Using latest checkpoint for English: ./results/en_xlm_roberta_soft/checkpoint-1224\nUsing latest checkpoint for Spanish: ./results/es_xlm_roberta_soft/checkpoint-1224\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## HARD Predictions","metadata":{}},{"cell_type":"code","source":"def predict_hard_labels_from_soft_model(tweets, ids, model, tokenizer, label_classes, output_file):\n    \"\"\"\n    Uses the soft model to predict a single hard label: \"YES\" or \"NO\".\n    - Assigns the label with the higher probability.\n    \"\"\"\n    # model.eval()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")#faster on gpu\n    model.to(device)\n\n    results = []\n\n    for tweet, tweet_id in zip(tweets, ids):\n        # encoding = tokenizer(text=tweet, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n        \n        encoding = tokenizer(tweet, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n        encoding = {key: val.to(device) for key, val in encoding.items()}\n        with torch.no_grad():\n            outputs = model(**encoding)\n\n        logits = outputs.logits.squeeze()\n        probs = torch.sigmoid(logits).cpu().numpy()\n\n        # Pick the label with the highest probability (YES or NO)\n        max_index = int(probs.argmax())\n        predicted_label = label_classes[max_index]\n\n        results.append({\n            \"test_case\": \"EXIST2025\",\n            \"id\": tweet_id,\n            \"value\": [predicted_label]  # Only one label\n        })\n    print(f\"Hard label predictions saved to {output_file}\")\n\npredict_hard_labels_from_soft_model(english_dev_tweets, english_dev_ids, model_en, tokenizer, label_classes, \"EXIST2025_dev_predictions_hard_merged_en.json\")\npredict_hard_labels_from_soft_model(spanish_dev_tweets, spanish_dev_ids, model_es, tokenizer, label_classes, \"EXIST2025_dev_predictions_hard_merged_es.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T18:44:36.231645Z","iopub.execute_input":"2025-05-11T18:44:36.231915Z","iopub.status.idle":"2025-05-11T18:44:53.507558Z","shell.execute_reply.started":"2025-05-11T18:44:36.231898Z","shell.execute_reply":"2025-05-11T18:44:53.506654Z"}},"outputs":[{"name":"stdout","text":"Hard label predictions saved to EXIST2025_dev_predictions_hard_merged_en.json\nHard label predictions saved to EXIST2025_dev_predictions_hard_merged_es.json\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/working/EXIST2025_dev_predictions_hard_merged_es.json\", \"r\", encoding=\"utf-8\") as f:\n    es_data = json.load(f)\nwith open(\"/kaggle/working/EXIST2025_dev_predictions_hard_merged_en.json\", \"r\", encoding=\"utf-8\") as f:\n    en_data = json.load(f)\n\n# Assuming both files contain lists of predictions, merge them\nif isinstance(es_data, list) and isinstance(en_data, list):\n    merged_data = es_data + en_data\nelse:\n    raise ValueError(\"JSON structure is not a list. Ensure both files contain lists.\")\n\nimport json\n\npredictions = merged_data\n\nconverted = []\nfor entry in predictions:\n    # Convert the \"value\" list to a single string (first label only)\n    new_entry = {\n        \"test_case\": entry[\"test_case\"],\n        \"id\": entry[\"id\"],\n        \"value\": entry[\"value\"][0] if isinstance(entry[\"value\"], list) else entry[\"value\"]\n    }\n    converted.append(new_entry)\noutput_file = \"EXIST2025_dev_predictions_merged_hard_flat.json\"\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    json.dump(converted, f, indent=4)\n\nprint(f\"Predictions converted to gold format and saved to {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T18:45:04.377415Z","iopub.execute_input":"2025-05-11T18:45:04.377733Z","iopub.status.idle":"2025-05-11T18:45:04.404050Z","shell.execute_reply.started":"2025-05-11T18:45:04.377712Z","shell.execute_reply":"2025-05-11T18:45:04.402838Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1319936071.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/EXIST2025_dev_predictions_hard_merged_es.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mes_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/EXIST2025_dev_predictions_hard_merged_en.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/EXIST2025_dev_predictions_hard_merged_es.json'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/EXIST2025_dev_predictions_hard_merged_es.json'","output_type":"error"}],"execution_count":34},{"cell_type":"code","source":"# Run inference on each tweet\noutput = []\nfor case_id, case_data in tqdm(test_data.items()):\n    if case_data['lang']=='es':\n        continue\n    tweet = case_data[\"tweet\"]\n\n    # Tokenize the tweet\n    inputs = tokenizer(tweet, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n    # Ensure the model and inputs are on the same device (use GPU if available)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    inputs = {key: val.to(device) for key, val in inputs.items()}\n\n    # Get model predictions\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Get the predicted class index\n    logits = outputs.logits\n    predicted_class_idx = torch.argmax(logits, dim=1).item()\n\n    # Map the predicted class index to label\n    predicted_label = id2label[predicted_class_idx]\n\n    # Append the result to the output list\n    output.append({\n        \"test_case\": \"EXIST2025\",\n        \"id\": case_data[\"id_EXIST\"],\n        \"value\": predicted_label\n    })\n\n# Save the results to an output JSON file\noutput_json_file = \"distil_en_hard_predictions_mergedlang.json\"  # Specify the output file path\nwith open(output_json_file, \"w\") as f:\n    json.dump(output, f, indent=4)\n\nprint(f\"Results saved to {output_json_file}\")\n\nfrom pyevall.evaluation import PyEvALLEvaluation\nfrom pyevall.utils.utils import PyEvALLUtils\npredictions = \"/kaggle/working/distil_en_hard_predictions_mergedlang.json\"         \ngold = \"/kaggle/input/existdatasets/EXIST2025_dev_task1_2_gold_hard.json\" \ntest = PyEvALLEvaluation() \nparams= dict() \nparams[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED  \nmetrics=[\"ICM\", \"ICMNorm\" ,\"FMeasure\"]                  # for hard        \nreport= test.evaluate(predictions, gold, metrics, **params) \nreport.print_report()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from numba import cuda\ncuda.select_device(0)\ncuda.close()\ncuda.select_device(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:41:15.389884Z","iopub.execute_input":"2025-04-24T09:41:15.390165Z","execution_failed":"2025-04-24T09:41:20.729Z"}},"outputs":[{"name":"stderr","text":"--- Logging error ---\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 1114, in emit\n    self.flush()\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 1094, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n    ColabKernelApp.launch_instance()\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n    res = shell.run_cell(\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n    result = self._run_cell(\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3148, in run_cell_async\n    self.events.trigger('pre_run_cell', info)\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/events.py\", line 89, in trigger\n    func(*args, **kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 559, in _resume_backend\n    self._logger.info(\"resuming backend\")  # type: ignore\nMessage: 'resuming backend'\nArguments: ()\n","output_type":"stream"},{"name":"stdout","text":"2025-04-24 09:41:17,568 - numba.cuda.cudadrv.driver - INFO -   ensure_initialized() - init\n2025-04-24 09:41:17,570 - numba.cuda.cudadrv.driver - INFO -                reset() - reset context of device 0\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# To Generate Prediction File","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T12:46:45.392505Z","iopub.execute_input":"2025-04-23T12:46:45.392871Z","iopub.status.idle":"2025-04-23T12:46:45.853415Z","shell.execute_reply.started":"2025-04-23T12:46:45.392843Z","shell.execute_reply":"2025-04-23T12:46:45.852748Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import json\n\n# Load the dev dataset\nwith open(\"/kaggle/input/existdatasets/EXIST2025_dev.json\", \"r\", encoding=\"utf-8\") as f:\n    dev_data = json.load(f)\n\n# Split into English & Spanish\nenglish_dev_tweets = []\nenglish_dev_ids = []\nspanish_dev_tweets = []\nspanish_dev_ids = []\n\nfor entry in dev_data.values():\n    # tweet = entry[\"tweet\"]\n    # annotator_info = {\n    #     # \"country\": entry.get(\"countries_annotators\", []),\n    #     \"study_level\": entry.get(\"study_levels_annotators\", []),\n    #     \"ethnicity\": entry.get(\"ethnicities_annotators\", []),\n    #     # \"age\": entry.get(\"age_annotators\", []),\n    #     # \"gender\": entry.get(\"gender_annotators\", [])\n    # }\n\n    # # Flatten and format metadata into string\n    # annotator_str = \" | \".join(\n    #     f\"{key}: {', '.join(map(str, value))}\" for key, value in annotator_info.items()\n    # )\n    # full_text = f\"{tweet} [ANNOTATORS] {annotator_str}\"\n    tweet_id = entry[\"id_EXIST\"]\n    tweet = entry[\"tweet\"]\n    lang = entry[\"lang\"]\n\n    if lang == \"en\":\n        english_dev_tweets.append(tweet)\n        english_dev_ids.append(tweet_id)\n    elif lang == \"es\":\n        spanish_dev_tweets.append(tweet)\n        spanish_dev_ids.append(tweet_id)\n\n# Debugging: Check split sizes\nprint(f\"English Dev Samples: {len(english_dev_tweets)}\")\nprint(f\"Spanish Dev Samples: {len(spanish_dev_tweets)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:44:09.290788Z","iopub.execute_input":"2025-04-24T09:44:09.291084Z","iopub.status.idle":"2025-04-24T09:44:09.337347Z","shell.execute_reply.started":"2025-04-24T09:44:09.291064Z","shell.execute_reply":"2025-04-24T09:44:09.336667Z"}},"outputs":[{"name":"stdout","text":"English Dev Samples: 489\nSpanish Dev Samples: 549\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(english_dev_tweets[10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T00:21:46.502469Z","iopub.execute_input":"2025-04-24T00:21:46.503228Z","iopub.status.idle":"2025-04-24T00:21:46.509013Z","shell.execute_reply.started":"2025-04-24T00:21:46.503195Z","shell.execute_reply":"2025-04-24T00:21:46.508360Z"}},"outputs":[{"name":"stdout","text":"@esjayXX @EcuadorianMum @monsalore They so remind me of MGTOW (Men go their own way) in US full of men who hate women obessively talking about women. Just go your own way, we don't fcking care. And the envy pics of creepy men not having lunch but staring into their camera alone or from a women's loo!\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import os\nfrom transformers import BertForSequenceClassification, AutoModelForSequenceClassification, AutoTokenizer\n\n# Function to get the latest checkpoint\ndef get_latest_checkpoint(directory=\"./results\"):\n    checkpoints = [d for d in os.listdir(directory) if d.startswith(\"checkpoint-\")]\n    if not checkpoints:\n        raise ValueError(f\"No checkpoints found in {directory}\")\n    latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))[-1]\n    return os.path.join(directory, latest_checkpoint)\n\n# Load the best model checkpoint for English and Spanish\nlatest_checkpoint_en = get_latest_checkpoint(\"./results/en_xlm_roberta_fb_aeda\")\nlatest_checkpoint_es = get_latest_checkpoint(\"./results/es_xlm_roberta_fb_aeda\")\n\nprint(f\"Using latest checkpoint for English: {latest_checkpoint_en}\")\nprint(f\"Using latest checkpoint for Spanish: {latest_checkpoint_es}\")\n\n# Load models\n# model_en = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n# tokenizer_en = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n# model_es = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_es\")\n# tokenizer_es = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_es\")\n# Load models\nmodel_en = AutoModelForSequenceClassification.from_pretrained(latest_checkpoint_en)\nmodel_es = AutoModelForSequenceClassification.from_pretrained(latest_checkpoint_es)\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n# tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\ntokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:45:42.511231Z","iopub.execute_input":"2025-04-24T09:45:42.511905Z","iopub.status.idle":"2025-04-24T09:45:44.287273Z","shell.execute_reply.started":"2025-04-24T09:45:42.511881Z","shell.execute_reply":"2025-04-24T09:45:44.286663Z"}},"outputs":[{"name":"stdout","text":"Using latest checkpoint for English: ./results/en_xlm_roberta_fb_aeda/checkpoint-865\nUsing latest checkpoint for Spanish: ./results/es_xlm_roberta_fb_aeda/checkpoint-865\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### hard","metadata":{}},{"cell_type":"code","source":"# Check for None or empty tweets in Spanish data\nfor i, (tweet, tweet_id) in enumerate(zip(spanish_dev_tweets, spanish_dev_ids)):\n    if not tweet:\n        print(f\"Empty tweet at index {i}, ID: {tweet_id}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:01:03.405555Z","iopub.execute_input":"2025-04-24T09:01:03.406453Z","iopub.status.idle":"2025-04-24T09:01:03.411612Z","shell.execute_reply.started":"2025-04-24T09:01:03.406420Z","shell.execute_reply":"2025-04-24T09:01:03.410826Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def predict_hard_labels_from_soft_model(tweets, ids, model, tokenizer, label_classes, output_file):\n    \"\"\"\n    Uses the soft model to predict a single hard label: \"YES\" or \"NO\".\n    - Assigns the label with the higher probability.\n    \"\"\"\n    # model.eval()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")#faster on gpu\n    model.to(device)\n\n    results = []\n\n    for tweet, tweet_id in zip(tweets, ids):\n        # encoding = tokenizer(text=tweet, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n        \n        encoding = tokenizer(tweet, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n        encoding = {key: val.to(device) for key, val in encoding.items()}\n        with torch.no_grad():\n            outputs = model(**encoding)\n\n        logits = outputs.logits.squeeze()\n        probs = torch.sigmoid(logits).cpu().numpy()\n\n        # Pick the label with the highest probability (YES or NO)\n        max_index = int(probs.argmax())\n        predicted_label = label_classes[max_index]\n\n        results.append({\n            \"test_case\": \"EXIST2025\",\n            \"id\": tweet_id,\n            \"value\": [predicted_label]  # Only one label\n        })\n    print(f\"Hard label predictions saved to {output_file}\")\n\npredict_hard_labels_from_soft_model(english_dev_tweets, english_dev_ids, model_en, tokenizer, label_classes, \"EXIST2025_dev_predictions_hard_merged_en.json\")\npredict_hard_labels_from_soft_model(spanish_dev_tweets, spanish_dev_ids, model_es, tokenizer, label_classes, \"EXIST2025_dev_predictions_hard_merged_es.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:59:49.455288Z","iopub.execute_input":"2025-04-24T09:59:49.455883Z","iopub.status.idle":"2025-04-24T10:00:07.248593Z","shell.execute_reply.started":"2025-04-24T09:59:49.455859Z","shell.execute_reply":"2025-04-24T10:00:07.247871Z"}},"outputs":[{"name":"stdout","text":"Hard label predictions saved to EXIST2025_dev_predictions_hard_merged_en.json\nHard label predictions saved to EXIST2025_dev_predictions_hard_merged_es.json\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import json\n\n# Load the Spanish predictions\nwith open(\"/kaggle/working/EXIST2025_dev_predictions_hard_merged_es.json\", \"r\", encoding=\"utf-8\") as f:\n    es_data = json.load(f)\n\n# Load the English predictions\nwith open(\"/kaggle/working/EXIST2025_dev_predictions_hard_merged_en.json\", \"r\", encoding=\"utf-8\") as f:\n    en_data = json.load(f)\n\n# Assuming both files contain lists of predictions, merge them\nif isinstance(es_data, list) and isinstance(en_data, list):\n    merged_data = es_data + en_data\nelse:\n    raise ValueError(\"JSON structure is not a list. Ensure both files contain lists.\")\n\nimport json\n\npredictions = merged_data\n\nconverted = []\nfor entry in predictions:\n    # Convert the \"value\" list to a single string (first label only)\n    new_entry = {\n        \"test_case\": entry[\"test_case\"],\n        \"id\": entry[\"id\"],\n        \"value\": entry[\"value\"][0] if isinstance(entry[\"value\"], list) else entry[\"value\"]\n    }\n    converted.append(new_entry)\noutput_file = \"EXIST2025_dev_predictions_merged_hard_flat.json\"\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    json.dump(converted, f, indent=4)\n\nprint(f\"Predictions converted to gold format and saved to {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T10:01:33.423956Z","iopub.execute_input":"2025-04-24T10:01:33.424286Z","iopub.status.idle":"2025-04-24T10:01:33.439840Z","shell.execute_reply.started":"2025-04-24T10:01:33.424263Z","shell.execute_reply":"2025-04-24T10:01:33.439155Z"}},"outputs":[{"name":"stdout","text":"Predictions converted to gold format and saved to EXIST2025_dev_predictions_merged_hard_flat.json\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import torch\nimport json\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T10:01:35.816477Z","iopub.execute_input":"2025-04-24T10:01:35.817059Z","iopub.status.idle":"2025-04-24T10:01:35.820844Z","shell.execute_reply.started":"2025-04-24T10:01:35.817035Z","shell.execute_reply":"2025-04-24T10:01:35.819932Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"!pip install pyEvall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:47:03.209322Z","iopub.execute_input":"2025-04-24T09:47:03.210016Z","iopub.status.idle":"2025-04-24T09:47:06.039463Z","shell.execute_reply.started":"2025-04-24T09:47:03.209984Z","shell.execute_reply":"2025-04-24T09:47:06.038387Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pyEvall in /usr/local/lib/python3.11/dist-packages (0.1.78)\nRequirement already satisfied: jsbeautifier==1.14.9 in /usr/local/lib/python3.11/dist-packages (from pyEvall) (1.14.9)\nRequirement already satisfied: jsonschema==4.23.0 in /usr/local/lib/python3.11/dist-packages (from pyEvall) (4.23.0)\nRequirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from pyEvall) (1.26.4)\nRequirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.11/dist-packages (from pyEvall) (2.2.3)\nRequirement already satisfied: setuptools==69.5.1 in /usr/local/lib/python3.11/dist-packages (from pyEvall) (69.5.1)\nRequirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/dist-packages (from pyEvall) (0.9.0)\nRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from jsbeautifier==1.14.9->pyEvall) (1.17.0)\nRequirement already satisfied: editorconfig>=0.12.2 in /usr/local/lib/python3.11/dist-packages (from jsbeautifier==1.14.9->pyEvall) (0.17.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema==4.23.0->pyEvall) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema==4.23.0->pyEvall) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema==4.23.0->pyEvall) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema==4.23.0->pyEvall) (0.22.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->pyEvall) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->pyEvall) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->pyEvall) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->pyEvall) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->pyEvall) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->pyEvall) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->pyEvall) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->pyEvall) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->pyEvall) (2025.2)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema==4.23.0->pyEvall) (4.13.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->pyEvall) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->pyEvall) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4->pyEvall) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4->pyEvall) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4->pyEvall) (2024.2.0)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from pyevall.evaluation import PyEvALLEvaluation\nfrom pyevall.utils.utils import PyEvALLUtils\npredictions = \"/kaggle/working/EXIST2025_dev_predictions_merged_hard_flat.json\"         \ngold = \"/kaggle/input/existdatasets/EXIST2025_dev_task1_2_gold_hard.json\" \ntest = PyEvALLEvaluation() \nparams= dict() \nparams[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED  \nmetrics=[\"ICM\", \"ICMNorm\" ,\"FMeasure\"]                  # for hard        \nreport= test.evaluate(predictions, gold, metrics, **params) \nreport.print_report()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T10:01:38.701196Z","iopub.execute_input":"2025-04-24T10:01:38.701789Z","iopub.status.idle":"2025-04-24T10:01:40.234090Z","shell.execute_reply.started":"2025-04-24T10:01:38.701766Z","shell.execute_reply":"2025-04-24T10:01:40.233337Z"}},"outputs":[{"name":"stdout","text":"2025-04-24 10:01:38,707 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n2025-04-24 10:01:38,799 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n2025-04-24 10:01:39,136 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n2025-04-24 10:01:39,139 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n2025-04-24 10:01:39,497 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n2025-04-24 10:01:39,818 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n{\n  \"metrics\": {\n    \"ICM\": {\n      \"name\": \"Information Contrast model\",\n      \"acronym\": \"ICM\",\n      \"description\": \"Coming soon!\",\n      \"status\": \"OK\",\n      \"results\": {\n        \"test_cases\": [{\n          \"name\": \"EXIST2025\",\n          \"average\": -0.4250858042027351\n        }],\n        \"average_per_test_case\": -0.4250858042027351\n      }\n    },\n    \"ICMNorm\": {\n      \"name\": \"Normalized Information Contrast Model\",\n      \"acronym\": \"ICM-Norm\",\n      \"description\": \"Coming soon!\",\n      \"status\": \"OK\",\n      \"results\": {\n        \"test_cases\": [{\n          \"name\": \"EXIST2025\",\n          \"average\": 0.3670717959176243\n        }],\n        \"average_per_test_case\": 0.3670717959176243\n      }\n    },\n    \"FMeasure\": {\n      \"name\": \"F-Measure\",\n      \"acronym\": \"F1\",\n      \"description\": \"Coming soon!\",\n      \"status\": \"OK\",\n      \"results\": {\n        \"test_cases\": [{\n          \"name\": \"EXIST2025\",\n          \"classes\": {\n            \"JUDGEMENTAL\": 0.24137931034482757,\n            \"NO\": 0.7603160667251976,\n            \"REPORTED\": 0.21897810218978103,\n            \"DIRECT\": 0.513347022587269\n          },\n          \"average\": 0.4335051254617688\n        }],\n        \"average_per_test_case\": 0.4335051254617688\n      }\n    }\n  },\n  \"files\": {\n    \"EXIST2025_dev_predictions_merged_hard_flat.json\": {\n      \"name\": \"EXIST2025_dev_predictions_merged_hard_flat.json\",\n      \"status\": \"OK\",\n      \"gold\": false,\n      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_predictions_merged_hard_flat.json.\",\n      \"errors\": {}\n    },\n    \"EXIST2025_dev_task1_2_gold_hard.json\": {\n      \"name\": \"EXIST2025_dev_task1_2_gold_hard.json\",\n      \"status\": \"OK\",\n      \"gold\": true,\n      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_task1_2_gold_hard.json.\",\n      \"errors\": {}\n    }\n  }\n}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"### SOFT\n","metadata":{}},{"cell_type":"code","source":"def predict_on_dev(tweets, ids, model, tokenizer, label_classes, output_file):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")#faster on gpu\n    model.to(device)\n    model.eval()\n    results = []\n\n    for tweet, tweet_id in zip(tweets, ids):\n        # encoding = tokenizer(tweet, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n        encoding = tokenizer(tweet, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n        encoding = {key: val.to(device) for key, val in encoding.items()}\n\n        with torch.no_grad():\n            outputs = model(**encoding)\n\n        logits = outputs.logits.squeeze()\n        probs = torch.sigmoid(logits).cpu().numpy()\n\n        # Convert probabilities to dictionary format and sort by highest probability\n        soft_label_dict = {label_classes[i]: float(probs[i]) for i in range(len(label_classes))}\n        sorted_soft_label_dict = dict(sorted(soft_label_dict.items(), key=lambda item: item[1], reverse=True))  # Sort descending\n\n        results.append({\n            \"test_case\": \"EXIST2025\",\n            \"id\": tweet_id,\n            \"value\": sorted_soft_label_dict  # Rename \"soft_label\" to \"value\" and sort it\n        })\n\n    # Save results\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(results, f, indent=4)\n\n    print(f\"Predictions saved to {output_file}\")\n    \n# label_classes = CORRECT_LABELS\n\n\n# Run predictions\npredict_on_dev(english_dev_tweets, english_dev_ids, model_en, tokenizer, label_classes, \"EXIST2025_dev_predictions_soft_merged_en.json\")\npredict_on_dev(spanish_dev_tweets, spanish_dev_ids, model_es, tokenizer, label_classes, \"EXIST2025_dev_predictions_soft_merged_es.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:58:07.584404Z","iopub.execute_input":"2025-04-24T08:58:07.584947Z","iopub.status.idle":"2025-04-24T08:58:26.638287Z","shell.execute_reply.started":"2025-04-24T08:58:07.584913Z","shell.execute_reply":"2025-04-24T08:58:26.637497Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to EXIST2025_dev_predictions_soft_merged_en.json\nPredictions saved to EXIST2025_dev_predictions_soft_merged_es.json\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import json\n\n# Load the Spanish predictions\nwith open(\"/kaggle/working/EXIST2025_dev_predictions_soft_merged_es.json\", \"r\", encoding=\"utf-8\") as f:\n    es_data = json.load(f)\n\n# Load the English predictions\nwith open(\"/kaggle/working/EXIST2025_dev_predictions_soft_merged_en.json\", \"r\", encoding=\"utf-8\") as f:\n    en_data = json.load(f)\n\n# Assuming both files contain lists of predictions, merge them\nif isinstance(es_data, list) and isinstance(en_data, list):\n    merged_data = es_data + en_data\nelse:\n    raise ValueError(\"JSON structure is not a list. Ensure both files contain lists.\")\n\n# Save to a new file\noutput_filename = \"EXIST2025_dev_predictions_merged_soft_distilroberta.json\"\nwith open(output_filename, \"w\", encoding=\"utf-8\") as f:\n    json.dump(merged_data, f, indent=4, ensure_ascii=False)\n\nprint(f\"Merging complete! Saved to {output_filename}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:58:33.864660Z","iopub.execute_input":"2025-04-24T08:58:33.864954Z","iopub.status.idle":"2025-04-24T08:58:33.892283Z","shell.execute_reply.started":"2025-04-24T08:58:33.864932Z","shell.execute_reply":"2025-04-24T08:58:33.891753Z"}},"outputs":[{"name":"stdout","text":"Merging complete! Saved to EXIST2025_dev_predictions_merged_soft_distilroberta.json\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import json\nimport numpy as np\n\n# Load your predictions file\nwith open('EXIST2025_dev_predictions_merged_soft_distilroberta.json', 'r') as f:\n    predictions = json.load(f)\n\n# Define the snapping values (multiples of 1/6)\nsnap_vals = np.array([i / 6 for i in range(7)])  # [0.0, 0.1667, ..., 1.0]\n\ndef snap_to_nearest_sixth(value):\n    return float(snap_vals[np.argmin(np.abs(snap_vals - value))])\n\n# Snap each value in the 'value' dict\nfor entry in predictions:\n    entry['value'] = {k: snap_to_nearest_sixth(v) for k, v in entry['value'].items()}\n\n# Save the snapped predictions to a new file\nwith open('EXIST2025_dev_predictions_snapped_soft.json', 'w') as f:\n    json.dump(predictions, f, indent=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:58:35.744729Z","iopub.execute_input":"2025-04-24T08:58:35.745338Z","iopub.status.idle":"2025-04-24T08:58:35.788328Z","shell.execute_reply.started":"2025-04-24T08:58:35.745313Z","shell.execute_reply":"2025-04-24T08:58:35.787810Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# print(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T23:18:46.332736Z","iopub.execute_input":"2025-04-23T23:18:46.332969Z","iopub.status.idle":"2025-04-23T23:18:46.336832Z","shell.execute_reply.started":"2025-04-23T23:18:46.332952Z","shell.execute_reply":"2025-04-23T23:18:46.336282Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from pyevall.evaluation import PyEvALLEvaluation\nfrom pyevall.utils.utils import PyEvALLUtils\npredictions = \"/kaggle/working/EXIST2025_dev_predictions_snapped_soft.json\"         \ngold = \"/kaggle/input/existdatasets/EXIST2025_dev_task1_2_gold_soft.json\" \ntest = PyEvALLEvaluation() \nparams= dict() \nparams[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED  \nmetrics=[\"ICMSoft\", \"ICMSoftNorm\", \"CrossEntropy\"]      # for soft    \nreport= test.evaluate(predictions, gold, metrics, **params) \nreport.print_report()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:58:38.219326Z","iopub.execute_input":"2025-04-24T08:58:38.220180Z","iopub.status.idle":"2025-04-24T08:58:41.660135Z","shell.execute_reply.started":"2025-04-24T08:58:38.220153Z","shell.execute_reply":"2025-04-24T08:58:41.659486Z"}},"outputs":[{"name":"stdout","text":"2025-04-24 08:58:38,226 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICMSoft', 'ICMSoftNorm', 'CrossEntropy']\n2025-04-24 08:58:38,503 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n2025-04-24 08:58:39,453 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM-Soft Normalized evaluation method\n2025-04-24 08:58:39,456 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n2025-04-24 08:58:40,380 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n2025-04-24 08:58:41,274 - pyevall.metrics.metrics - INFO -             evaluate() - Executing Cross Entropy evaluation method\n{\n  \"metrics\": {\n    \"ICMSoft\": {\n      \"name\": \"Information Contrast Model Soft\",\n      \"acronym\": \"ICM-Soft\",\n      \"description\": \"Coming soon!\",\n      \"status\": \"OK\",\n      \"results\": {\n        \"test_cases\": [{\n          \"name\": \"EXIST2025\",\n          \"average\": -1.6889327393654883\n        }],\n        \"average_per_test_case\": -1.6889327393654883\n      }\n    },\n    \"ICMSoftNorm\": {\n      \"name\": \"Normalized Information Contrast Model Soft\",\n      \"acronym\": \"ICM-Soft-Norm\",\n      \"description\": \"Coming soon!\",\n      \"status\": \"OK\",\n      \"results\": {\n        \"test_cases\": [{\n          \"name\": \"EXIST2025\",\n          \"average\": 0.3713930100457046\n        }],\n        \"average_per_test_case\": 0.3713930100457046\n      }\n    },\n    \"CrossEntropy\": {\n      \"name\": \"Cross Entropy\",\n      \"acronym\": \"CE\",\n      \"description\": \"Coming soon!\",\n      \"status\": \"OK\",\n      \"results\": {\n        \"test_cases\": [{\n          \"name\": \"EXIST2025\",\n          \"average\": 1.85885356958642\n        }],\n        \"average_per_test_case\": 1.85885356958642\n      }\n    }\n  },\n  \"files\": {\n    \"EXIST2025_dev_predictions_snapped_soft.json\": {\n      \"name\": \"EXIST2025_dev_predictions_snapped_soft.json\",\n      \"status\": \"OK\",\n      \"gold\": false,\n      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_predictions_snapped_soft.json.\",\n      \"errors\": {}\n    },\n    \"EXIST2025_dev_task1_2_gold_soft.json\": {\n      \"name\": \"EXIST2025_dev_task1_2_gold_soft.json\",\n      \"status\": \"OK\",\n      \"gold\": true,\n      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_task1_2_gold_soft.json.\",\n      \"errors\": {}\n    }\n  }\n}\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"### AEDA AUGMENTATION","metadata":{}},{"cell_type":"markdown","source":"First create combined dataset with gold labels","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset\n\n# AEDA helper\nPUNCTUATIONS = ['.', ',', '!', '?', ';', ':']\ndef aeda(sentence, num_insertions=3):\n    words = sentence.split()\n    if not words:\n        return sentence\n    new_words = words.copy()\n    for _ in range(num_insertions):\n        insert_pos = random.randint(0, len(new_words))\n        punct = random.choice(PUNCTUATIONS)\n        new_words.insert(insert_pos, punct)\n    return ' '.join(new_words)\n\n# === Load Data ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\n\n# === Process Tweets & Apply AEDA ===\ndef process_data_with_soft_labels(data, augment=True, augment_n=2):\n    tweets, labels, ids = [], [], []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in label_classes]\n\n        # Original tweet\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n        # Augmented tweets\n        if augment:\n            for i in range(augment_n):\n                augmented_tweet = aeda(tweet)\n                tweets.append(augmented_tweet)\n                labels.append(soft_label_vector)\n                ids.append(f\"{tweet_id}_aug{i+1}\")\n\n    return tweets, labels, ids\n\n# Process both languages\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# === Tokenizer ===\ntokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n\n# === Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": label\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\nprint(f\"✅ English train set size: {len(train_dataset_en)} (with augmentation)\")\nprint(f\"✅ Spanish train set size: {len(train_dataset_es)} (with augmentation)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:03:52.860203Z","iopub.execute_input":"2025-04-23T16:03:52.860731Z","iopub.status.idle":"2025-04-23T16:03:55.534496Z","shell.execute_reply.started":"2025-04-23T16:03:52.860709Z","shell.execute_reply":"2025-04-23T16:03:55.533910Z"}},"outputs":[{"name":"stdout","text":"✅ English train set size: 16608 (with augmentation)\n✅ Spanish train set size: 16608 (with augmentation)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### With underrepresented labels only","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset\nfrom collections import defaultdict\n\n# === AEDA helper ===\nPUNCTUATIONS = ['.', ',', '!', '?', ';', ':']\ndef aeda(sentence, num_insertions=3):\n    words = sentence.split()\n    if not words:\n        return sentence\n    new_words = words.copy()\n    for _ in range(num_insertions):\n        insert_pos = random.randint(0, len(new_words))\n        punct = random.choice(PUNCTUATIONS)\n        new_words.insert(insert_pos, punct)\n    return ' '.join(new_words)\n\n# === Load Data ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\nlabel_classes = [\"NO\", \"DIRECT\", \"REPORTED\", \"JUDGEMENTAL\"]\n\n# === Count Label Distribution ===\nlabel_counts = defaultdict(int)\nfor soft in gold_soft_dict.values():\n    max_label = max(soft, key=soft.get)\n    label_counts[max_label] += 1\n\n# === Identify underrepresented labels (you can tune this threshold) ===\navg_count = np.mean(list(label_counts.values()))\nunderrepresented_labels = [label for label, count in label_counts.items() if count < avg_count]\n\n# === Process Tweets & Augment Underrepresented Only ===\ndef process_data_with_soft_labels(data, augment=True, augment_n=2):\n    tweets, labels, ids = [], [], []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in label_classes]\n\n        # Original tweet\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n        # Determine primary label\n        main_label = max(soft_label_dict, key=soft_label_dict.get)\n\n        # Augment only if underrepresented\n        if augment and main_label in underrepresented_labels:\n            for i in range(augment_n):\n                augmented_tweet = aeda(tweet)\n                tweets.append(augmented_tweet)\n                labels.append(soft_label_vector)\n                ids.append(f\"{tweet_id}_aug{i+1}\")\n\n    return tweets, labels, ids\n\n# Process English and Spanish data\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:08:03.141158Z","iopub.execute_input":"2025-04-23T19:08:03.141477Z","iopub.status.idle":"2025-04-23T19:08:04.811439Z","shell.execute_reply.started":"2025-04-23T19:08:03.141451Z","shell.execute_reply":"2025-04-23T19:08:04.810730Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# === Tokenizer ===\n# model = AutoModelForSequenceClassification.from_pretrained(\n#         \"cardiffnlp/twitter-xlm-roberta-base\",\n#         num_labels=len(CORRECT_LABELS),\n#         problem_type=\"multi_label_classification\"\n#     )\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\n\n# === Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": label\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\nprint(f\"English train set size: {len(train_dataset_en)} (with selective augmentation)\")\nprint(f\"Spanish train set size: {len(train_dataset_es)} (with selective augmentation)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:08:12.637284Z","iopub.execute_input":"2025-04-23T19:08:12.637758Z","iopub.status.idle":"2025-04-23T19:08:13.804963Z","shell.execute_reply.started":"2025-04-23T19:08:12.637733Z","shell.execute_reply":"2025-04-23T19:08:13.804149Z"}},"outputs":[{"name":"stdout","text":"✅ English train set size: 9763 (with selective augmentation)\n✅ Spanish train set size: 9763 (with selective augmentation)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"train","metadata":{}},{"cell_type":"code","source":"CORRECT_LABELS = label_classes\n# === Train Model ===\ndef train_model(train_dataset, val_dataset, output_dir):\n\n\n    # model_en = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n# tokenizer_en = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n    model = AutoModelForSequenceClassification.from_pretrained(\n            \"cardiffnlp/twitter-xlm-roberta-base\",\n            num_labels=len(CORRECT_LABELS),\n            problem_type=\"multi_label_classification\"\n        )\n    # model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"FacebookAI/xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n\n    # model = BertForSequenceClassification.from_pretrained(\n    #     \"FacebookAI/xlm-roberta-base\",\n    #     num_labels=len(CORRECT_LABELS),\n    #     problem_type=\"multi_label_classification\"\n    # )\n\n    training_args = TrainingArguments(\n    output_dir=output_dir,\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_total_limit=1,\n)\n\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset\n    )\n\n    trainer.train()\n    return trainer\n\n# === Train English and Spanish models ===\n# trainer_en = train_model(train_dataset_en, val_dataset_en, output_dir=\"./results/en_xlm_roberta_aeda\")\ntrainer_es = train_model(train_dataset_es, val_dataset_es, output_dir=\"./results/es_xlm_roberta_aeda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:08:18.817243Z","iopub.execute_input":"2025-04-23T19:08:18.817514Z","iopub.status.idle":"2025-04-23T19:29:01.638049Z","shell.execute_reply.started":"2025-04-23T19:08:18.817494Z","shell.execute_reply":"2025-04-23T19:29:01.637273Z"}},"outputs":[{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1224' max='1224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1224/1224 20:39, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.503200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.469300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.450500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.436800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.425100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.416700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.394300</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.395900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.378800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.378500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.378400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### Combined training with AEDA","metadata":{}},{"cell_type":"markdown","source":"### BERT","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset\nfrom collections import defaultdict\n\n# === AEDA helper ===\nPUNCTUATIONS = ['.', ',', '!', '?', ';', ':']\ndef aeda(sentence, num_insertions=3):\n    words = sentence.split()\n    if not words:\n        return sentence\n    new_words = words.copy()\n    for _ in range(num_insertions):\n        insert_pos = random.randint(0, len(new_words))\n        punct = random.choice(PUNCTUATIONS)\n        new_words.insert(insert_pos, punct)\n    return ' '.join(new_words)\n\n# === Load Data ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\nlabel_classes = [\"NO\", \"DIRECT\", \"REPORTED\", \"JUDGEMENTAL\"]\n\n# === Count Label Distribution ===\nlabel_counts = defaultdict(int)\nfor soft in gold_soft_dict.values():\n    max_label = max(soft, key=soft.get)\n    label_counts[max_label] += 1\n\n# === Identify underrepresented labels (you can tune this threshold) ===\navg_count = np.mean(list(label_counts.values()))\nunderrepresented_labels = [label for label, count in label_counts.items() if count < avg_count]\n\n# === Process Tweets & Augment Underrepresented Only ===\ndef process_data_with_soft_labels(data, augment=True, augment_n=2):\n    tweets, labels, ids = [], [], []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in label_classes]\n\n        # Original tweet\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n        # Determine primary label\n        main_label = max(soft_label_dict, key=soft_label_dict.get)\n\n        # Augment only if underrepresented\n        if augment and main_label in underrepresented_labels:\n            for i in range(augment_n):\n                augmented_tweet = aeda(tweet)\n                tweets.append(augmented_tweet)\n                labels.append(soft_label_vector)\n                ids.append(f\"{tweet_id}_aug{i+1}\")\n\n    return tweets, labels, ids\n\n# Process English and Spanish data\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n# tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\n\n# === Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": label\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\nprint(f\"✅ English train set size: {len(train_dataset_en)} (with selective augmentation)\")\nprint(f\"✅ Spanish train set size: {len(train_dataset_es)} (with selective augmentation)\")\n\nCORRECT_LABELS = label_classes\nimport json\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\n\n# === Load Tweets ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\n\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\n\n# === Load gold_soft_train ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\n# Convert gold_soft to a dict for fast access\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\n\nCORRECT_LABELS = label_classes\n\n# === Process Tweets with Corresponding Soft Labels ===\ndef process_data_with_soft_labels(data):\n    tweets = []\n    labels = []\n    ids = []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue  # Skip if soft label not found\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in CORRECT_LABELS]\n\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n    return tweets, labels, ids\n\n# Process both English and Spanish tweets\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# === Custom Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": labels\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\n\n# === Train Model ===\ndef train_model(train_dataset, val_dataset, output_dir):\n\n\n    # model_en = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n# tokenizer_en = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n    # model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"cardiffnlp/twitter-xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n    # model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"FacebookAI/xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n\n    model = BertForSequenceClassification.from_pretrained(\n        \"bert-base-multilingual-cased\",\n        num_labels=len(CORRECT_LABELS),\n        problem_type=\"multi_label_classification\"\n    )\n\n    training_args = TrainingArguments(\n    output_dir=output_dir,\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_total_limit=1,\n)\n\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset\n    )\n\n    trainer.train()\n    return trainer\n\n# === Train English and Spanish models ===\ntrainer_en = train_model(train_dataset_en, val_dataset_en, output_dir=\"./results/en_mbert_aeda\")\ntrainer_es = train_model(train_dataset_es, val_dataset_es, output_dir=\"./results/es_mbert_aeda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:34:03.612270Z","iopub.execute_input":"2025-04-24T08:34:03.612521Z","iopub.status.idle":"2025-04-24T08:55:27.364184Z","shell.execute_reply.started":"2025-04-24T08:34:03.612505Z","shell.execute_reply":"2025-04-24T08:55:27.363662Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cd0907398d14ce7b8a9a625c9c1fc9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"785ff05512dd4326a127cd593c5acf8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee28a1ad217a40d980f6774dfcd8bd45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b4c5d1a63c45d282377b27a0c9176b"}},"metadata":{}},{"name":"stdout","text":"✅ English train set size: 9763 (with selective augmentation)\n✅ Spanish train set size: 9763 (with selective augmentation)\n","output_type":"stream"},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"name":"stdout","text":"2025-04-24 08:34:07,963 - huggingface_hub.file_download - WARNING - _download_to_tmp_and_move() - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fed2b667d4ce4a4b8e36509a40c9e76e"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='692' max='692' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [692/692 10:34, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.470300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.427800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.412200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.394400</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.386200</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.363500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='692' max='692' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [692/692 10:37, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.472600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.436800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.416800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.402600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.389000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.367200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### xlm Roberta fb","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset\nfrom collections import defaultdict\n\n# === AEDA helper ===\nPUNCTUATIONS = ['.', ',', '!', '?', ';', ':']\ndef aeda(sentence, num_insertions=3):\n    words = sentence.split()\n    if not words:\n        return sentence\n    new_words = words.copy()\n    for _ in range(num_insertions):\n        insert_pos = random.randint(0, len(new_words))\n        punct = random.choice(PUNCTUATIONS)\n        new_words.insert(insert_pos, punct)\n    return ' '.join(new_words)\n\n# === Load Data ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\nlabel_classes = [\"NO\", \"DIRECT\", \"REPORTED\", \"JUDGEMENTAL\"]\n\n# === Count Label Distribution ===\nlabel_counts = defaultdict(int)\nfor soft in gold_soft_dict.values():\n    max_label = max(soft, key=soft.get)\n    label_counts[max_label] += 1\n\n# === Identify underrepresented labels (you can tune this threshold) ===\navg_count = np.mean(list(label_counts.values()))\nunderrepresented_labels = [label for label, count in label_counts.items() if count < avg_count]\n\n# === Process Tweets & Augment Underrepresented Only ===\ndef process_data_with_soft_labels(data, augment=True, augment_n=2):\n    tweets, labels, ids = [], [], []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in label_classes]\n\n        # Original tweet\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n        # Determine primary label\n        main_label = max(soft_label_dict, key=soft_label_dict.get)\n\n        # Augment only if underrepresented\n        if augment and main_label in underrepresented_labels:\n            for i in range(augment_n):\n                augmented_tweet = aeda(tweet)\n                tweets.append(augmented_tweet)\n                labels.append(soft_label_vector)\n                ids.append(f\"{tweet_id}_aug{i+1}\")\n\n    return tweets, labels, ids\n\n# Process English and Spanish data\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n# tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\ntokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n\n# === Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": label\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\nprint(f\"✅ English train set size: {len(train_dataset_en)} (with selective augmentation)\")\nprint(f\"✅ Spanish train set size: {len(train_dataset_es)} (with selective augmentation)\")\n\nCORRECT_LABELS = label_classes\nimport json\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\n\n# === Load Tweets ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\n\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\n\n# === Load gold_soft_train ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\n# Convert gold_soft to a dict for fast access\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\n\n# Define labels\nCORRECT_LABELS = label_classes\n\n# === Process Tweets with Corresponding Soft Labels ===\ndef process_data_with_soft_labels(data):\n    tweets = []\n    labels = []\n    ids = []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue  # Skip if soft label not found\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in CORRECT_LABELS]\n\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n    return tweets, labels, ids\n\n# Process both English and Spanish tweets\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# === Custom Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": labels\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\n\n# === Train Model ===\ndef train_model(train_dataset, val_dataset, output_dir):\n\n\n    # model_en = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n# tokenizer_en = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n    # model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"cardiffnlp/twitter-xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n    model = AutoModelForSequenceClassification.from_pretrained(\n            \"FacebookAI/xlm-roberta-base\",\n            num_labels=len(CORRECT_LABELS),\n            problem_type=\"multi_label_classification\"\n        )\n# model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"FacebookAI/xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n\n    # model = BertForSequenceClassification.from_pretrained(\n    #     \"bert-base-multilingual-cased\",\n    #     num_labels=len(CORRECT_LABELS),\n    #     problem_type=\"multi_label_classification\"\n    # )\n\n    training_args = TrainingArguments(\n    output_dir=output_dir,\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=5,#increasing epocs for more data\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_total_limit=1,\n)\n\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset\n    )\n\n    trainer.train()\n    return trainer\n\n# === Train English and Spanish models ===\ntrainer_en = train_model(train_dataset_en, val_dataset_en, output_dir=\"./results/en_xlm_roberta_fb_aeda\")\ntrainer_es = train_model(train_dataset_es, val_dataset_es, output_dir=\"./results/es_xlm_roberta_fb_aeda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### HARD Training","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset\nfrom collections import defaultdict\n\n# === AEDA helper ===\nPUNCTUATIONS = ['.', ',', '!', '?', ';', ':']\ndef aeda(sentence, num_insertions=3):\n    words = sentence.split()\n    if not words:\n        return sentence\n    new_words = words.copy()\n    for _ in range(num_insertions):\n        insert_pos = random.randint(0, len(new_words))\n        punct = random.choice(PUNCTUATIONS)\n        new_words.insert(insert_pos, punct)\n    return ' '.join(new_words)\n\n# === Load Data ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_hard = json.load(f)\n\ngold_hard_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_hard}\nlabel_classes = [\"NO\", \"DIRECT\", \"REPORTED\", \"JUDGEMENTAL\"]\n\n# === Count Label Distribution ===\nlabel_counts = defaultdict(int)\nfor hard in gold_hard_dict.values():\n    label_counts[hard] += 1\n\n# === Identify underrepresented labels (you can tune this threshold) ===\navg_count = np.mean(list(label_counts.values()))\nunderrepresented_labels = [label for label, count in label_counts.items() if count < avg_count]\n\n# === Process Tweets & Augment Underrepresented Only ===\ndef process_data_with_soft_labels(data, augment=True, augment_n=2):\n    tweets, labels, ids = [], [], []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_hard_dict:\n            continue\n\n        hard_label = gold_hard_dict[tweet_id]\n        # soft_label_vector = [soft_label_dict.get(label, 0.0) for label in label_classes]\n\n        # Original tweet\n        tweets.append(tweet)\n        labels.append(hard_label)\n        ids.append(tweet_id)\n\n        # Determine primary label\n        main_label = max(soft_label_dict, key=soft_label_dict.get)\n\n        # Augment only if underrepresented\n        if augment and main_label in underrepresented_labels:\n            for i in range(augment_n):\n                augmented_tweet = aeda(tweet)\n                tweets.append(augmented_tweet)\n                labels.append(hard_label)\n                ids.append(f\"{tweet_id}_aug{i+1}\")\n\n    return tweets, labels, ids\n\n# Process English and Spanish data\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\n# tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n\n# === Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        label = self.labels[idx]\n        # label = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": label\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\nprint(f\"✅ English train set size: {len(train_dataset_en)} (with selective augmentation)\")\nprint(f\"✅ Spanish train set size: {len(train_dataset_es)} (with selective augmentation)\")\n\nCORRECT_LABELS = label_classes\nimport json\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\n\n# === Load Tweets ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\n\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\n\n# === Load gold_soft_train ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_hard.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\n# Convert gold_soft to a dict for fast access\ngold_hard_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\n\n# Define labels\nCORRECT_LABELS = label_classes\n\n# === Process Tweets with Corresponding Soft Labels ===\ndef process_data_with_soft_labels(data):\n    tweets = []\n    labels = []\n    ids = []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_hard_dict:\n            continue  # Skip if soft label not found\n\n        hard_label = gold_hard_dict[tweet_id]\n\n        # soft_label_vector = [soft_label_dict.get(label, 0.0) for label in CORRECT_LABELS]\n\n        tweets.append(tweet)\n        labels.append(hard_label)\n        ids.append(tweet_id)\n\n    return tweets, labels, ids\n\n# Process both English and Spanish tweets\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# === Custom Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        labels = self.labels[idx]\n        # label = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": labels\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\n\n# === Train Model ===\ndef train_model(train_dataset, val_dataset, output_dir):\n\n\n    # model_en = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n# tokenizer_en = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n    model = AutoModelForSequenceClassification.from_pretrained(\n            \"cardiffnlp/twitter-xlm-roberta-base\",\n            num_labels=len(CORRECT_LABELS),\n            problem_type=\"multi_label_classification\"\n        )\n    # model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"FacebookAI/xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n# model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"FacebookAI/xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n\n    # model = BertForSequenceClassification.from_pretrained(\n    #     \"bert-base-multilingual-cased\",\n    #     num_labels=len(CORRECT_LABELS),\n    #     problem_type=\"multi_label_classification\"\n    # )\n\n    training_args = TrainingArguments(\n    output_dir=output_dir,\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=5,#increasing epocs for more data\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_total_limit=1,\n)\n\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset\n    )\n\n    trainer.train()\n    return trainer\n\n# === Train English and Spanish models ===\ntrainer_en = train_model(train_dataset_en, val_dataset_en, output_dir=\"./results/en_xlm_roberta_fb_aeda_hard\")\ntrainer_es = train_model(train_dataset_es, val_dataset_es, output_dir=\"./results/es_xlm_roberta_fb_aeda_hard\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### EASE S Approach","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install nltk transformers torch tqdm\nimport nltk\nnltk.download('punkt', download_dir='/content/nltk_data')\nnltk.download('wordnet', download_dir='/content/nltk_data')\nnltk.data.path.append('/content/nltk_data')\nimport nltk\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('omw-1.4')  # Optional, for better synonym support\n\n\nnltk.download(\"punkt_tab\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport torch\nimport nltk\nimport random\nfrom tqdm import tqdm\nfrom nltk.corpus import wordnet\nfrom transformers import DistilBertForSequenceClassification, DistilBertTokenizer\nfrom torch.nn.functional import softmax\n\nnltk.download(\"punkt\")\nnltk.download(\"wordnet\")\n\n# Load tweet data (X)\nfile_path = \"/content/EXIST2025_training_translated_es.json\"\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\n# Load label data (Y)\nlabel_path = \"/content/EXIST2025_training_task1_3_gold_soft.json\"\nwith open(label_path, \"r\", encoding=\"utf-8\") as f:\n    labels = json.load(f)\n\n# Map from tweet ID to label\nlabel_map = {item[\"id\"]: item for item in labels}\n\n# Load Pretrained DistilBERT\nmodel_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\n# Augmentation functions\ndef extract_units(text):\n    sentences = nltk.sent_tokenize(text)\n    return sentences if len(sentences) > 1 else [text]\n\ndef sift_sentences(sentences):\n    return [s for s in sentences if len(s.split()) > 3]\n\ndef synonym_replacement(sentence, num_replacements=1):\n    words = sentence.split()\n    if len(words) < 2:\n        return sentence\n    words_to_replace = random.sample(words, min(num_replacements, len(words)))\n    for i, word in enumerate(words):\n        if word in words_to_replace:\n            syns = wordnet.synsets(word)\n            if syns:\n                synonyms = [lemma.name().replace('_', ' ') for lemma in syns[0].lemmas()]\n                if synonyms:\n                    words[i] = random.choice(synonyms)\n    return ' '.join(words)\n\n# Augmentation setup\naugmented_data = {}\naugmented_labels = []\naugmented_count = 0\nAUGMENT_LIMIT = 1000\nused_ids = []\n\n# Shuffle and iterate\nshuffled_items = list(data.items())\nrandom.shuffle(shuffled_items)\n\nfor key, value in tqdm(shuffled_items, desc=\"Augmenting Tweets\"):\n    if augmented_count >= AUGMENT_LIMIT:\n        break\n\n    original_id = value[\"id_EXIST\"]\n    if original_id in used_ids:\n        continue\n\n    original_text = value[\"tweet\"]\n    extracted_units = extract_units(original_text)\n    filtered_units = sift_sentences(extracted_units)\n\n    for i, unit in enumerate(filtered_units):\n        if augmented_count >= AUGMENT_LIMIT:\n            break\n\n        sr_unit = synonym_replacement(unit)\n        aug_key = f\"{key}_AUG_{i}\"\n        aug_id = f\"{original_id}_AUG_{i}\"\n\n        # Save augmented tweet\n        augmented_data[aug_key] = {\n            \"id_EXIST\": aug_id,\n            \"lang\": value[\"lang\"],\n            \"tweet\": sr_unit,\n            \"number_annotators\": value[\"number_annotators\"],\n            \"annotators\": value[\"annotators\"],\n            \"gender_annotators\": value[\"gender_annotators\"],\n            \"age_annotators\": value[\"age_annotators\"],\n            \"ethnicities_annotators\": value[\"ethnicities_annotators\"],\n            \"study_levels_annotators\": value[\"study_levels_annotators\"],\n            \"countries_annotators\": value[\"countries_annotators\"],\n            \"labels_task1_1\": value[\"labels_task1_1\"],\n            \"labels_task1_2\": value[\"labels_task1_2\"],\n            \"labels_task1_3\": value[\"labels_task1_3\"],\n            \"split\": \"AUG_EN\",\n        }\n\n        # Save corresponding label\n        if original_id in label_map:\n            original_label = label_map[original_id]\n            new_label = {\n                \"test_case\": original_label[\"test_case\"],\n                \"id\": aug_id,\n                \"value\": original_label[\"value\"]\n            }\n            augmented_labels.append(new_label)\n            augmented_count += 1\n\n    used_ids.append(original_id)\n\n# Merge original + augmented data\ndata.update(augmented_data)\nall_labels = labels + augmented_labels\n\n# Save tweet data\naugmented_file_path = \"EXIST2025_training_augmented_S_es.json\"\nwith open(augmented_file_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(data, f, ensure_ascii=False, indent=4)\n\n# Save label data\naugmented_label_path = \"EXIST2025_training_augmented_gold_es.json\"\nwith open(augmented_label_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(all_labels, f, ensure_ascii=False, indent=4)\n\n# Save used tweet IDs (optional, for reloading later)\nwith open(\"used_tweet_ids.json\", \"w\") as f:\n    json.dump(used_ids, f, indent=2)\n\nprint(f\"\\n✅ Augmentation Complete: {augmented_count} new samples added.\")\nprint(f\"Tweets saved at: {augmented_file_path}\")\nprint(f\"Labels saved at: {augmented_label_path}\")\nprint(f\"Used tweet IDs saved at: used_tweet_ids.json\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### MBert","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset\nfrom collections import defaultdict\n\n# === AEDA helper ===\nPUNCTUATIONS = ['.', ',', '!', '?', ';', ':']\ndef aeda(sentence, num_insertions=3):\n    words = sentence.split()\n    if not words:\n        return sentence\n    new_words = words.copy()\n    for _ in range(num_insertions):\n        insert_pos = random.randint(0, len(new_words))\n        punct = random.choice(PUNCTUATIONS)\n        new_words.insert(insert_pos, punct)\n    return ' '.join(new_words)\n\n# === Load Data ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\nlabel_classes = [\"NO\", \"DIRECT\", \"REPORTED\", \"JUDGEMENTAL\"]\n\n# === Count Label Distribution ===\nlabel_counts = defaultdict(int)\nfor soft in gold_soft_dict.values():\n    max_label = max(soft, key=soft.get)\n    label_counts[max_label] += 1\n\n# === Identify underrepresented labels (you can tune this threshold) ===\navg_count = np.mean(list(label_counts.values()))\nunderrepresented_labels = [label for label, count in label_counts.items() if count < avg_count]\n\n# === Process Tweets & Augment Underrepresented Only ===\ndef process_data_with_soft_labels(data, augment=True, augment_n=2):\n    tweets, labels, ids = [], [], []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in label_classes]\n\n        # Original tweet\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n        # Determine primary label\n        main_label = max(soft_label_dict, key=soft_label_dict.get)\n\n        # Augment only if underrepresented\n        if augment and main_label in underrepresented_labels:\n            for i in range(augment_n):\n                augmented_tweet = aeda(tweet)\n                tweets.append(augmented_tweet)\n                labels.append(soft_label_vector)\n                ids.append(f\"{tweet_id}_aug{i+1}\")\n\n    return tweets, labels, ids\n\n# Process English and Spanish data\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n# tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\n\n# === Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": label\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\nprint(f\"✅ English train set size: {len(train_dataset_en)} (with selective augmentation)\")\nprint(f\"✅ Spanish train set size: {len(train_dataset_es)} (with selective augmentation)\")\n\nCORRECT_LABELS = label_classes\nimport json\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\n\n# === Load Tweets ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_en.json\", \"r\", encoding=\"utf-8\") as f:\n    data_en = json.load(f)\n\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_translated_es.json\", \"r\", encoding=\"utf-8\") as f:\n    data_es = json.load(f)\n\n# === Load gold_soft_train ===\nwith open(\"/kaggle/input/existdatasets/EXIST2025_training_task1_2_gold_soft.json\", \"r\", encoding=\"utf-8\") as f:\n    gold_soft = json.load(f)\n\n# Convert gold_soft to a dict for fast access\ngold_soft_dict = {entry[\"id\"]: entry[\"value\"] for entry in gold_soft}\n\nCORRECT_LABELS = label_classes\n\n# === Process Tweets with Corresponding Soft Labels ===\ndef process_data_with_soft_labels(data):\n    tweets = []\n    labels = []\n    ids = []\n\n    for entry in data.values():\n        tweet_id = entry[\"id_EXIST\"]\n        tweet = entry[\"tweet\"]\n\n        if tweet_id not in gold_soft_dict:\n            continue  # Skip if soft label not found\n\n        soft_label_dict = gold_soft_dict[tweet_id]\n\n        soft_label_vector = [soft_label_dict.get(label, 0.0) for label in CORRECT_LABELS]\n\n        tweets.append(tweet)\n        labels.append(soft_label_vector)\n        ids.append(tweet_id)\n\n    return tweets, labels, ids\n\n# Process both English and Spanish tweets\ntweets_en, labels_en, ids_en = process_data_with_soft_labels(data_en)\ntweets_es, labels_es, ids_es = process_data_with_soft_labels(data_es)\n\n# === Custom Dataset Class ===\nclass TweetDataset(Dataset):\n    def __init__(self, texts, labels, ids, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.ids = ids\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tweet_id = self.ids[idx]\n        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            \"id\": tweet_id,\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": labels\n        }\n\n# === Train-validation split ===\ndef get_datasets(tweets, labels, ids):\n    train_texts, val_texts, train_labels, val_labels, train_ids, val_ids = train_test_split(\n        tweets, labels, ids, test_size=0.2, random_state=42\n    )\n    train_dataset = TweetDataset(train_texts, train_labels, train_ids, tokenizer)\n    val_dataset = TweetDataset(val_texts, val_labels, val_ids, tokenizer)\n    return train_dataset, val_dataset\n\n# === Create datasets ===\ntrain_dataset_en, val_dataset_en = get_datasets(tweets_en, labels_en, ids_en)\ntrain_dataset_es, val_dataset_es = get_datasets(tweets_es, labels_es, ids_es)\n\n\n# === Train Model ===\ndef train_model(train_dataset, val_dataset, output_dir):\n\n\n    # model_en = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n# tokenizer_en = AutoTokenizer.from_pretrained(\"/kaggle/working/distilroberta-base_mergedlang_en\")\n    # model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"cardiffnlp/twitter-xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n    # model = AutoModelForSequenceClassification.from_pretrained(\n    #         \"FacebookAI/xlm-roberta-base\",\n    #         num_labels=len(CORRECT_LABELS),\n    #         problem_type=\"multi_label_classification\"\n    #     )\n\n    model = BertForSequenceClassification.from_pretrained(\n        \"bert-base-multilingual-cased\",\n        num_labels=len(CORRECT_LABELS),\n        problem_type=\"multi_label_classification\"\n    )\n\n    training_args = TrainingArguments(\n    output_dir=output_dir,\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_total_limit=1,\n)\n\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset\n    )\n\n    trainer.train()\n    return trainer\n\n# === Train English and Spanish models ===\ntrainer_en = train_model(train_dataset_en, val_dataset_en, output_dir=\"./results/en_mbert_aeda\")\ntrainer_es = train_model(train_dataset_es, val_dataset_es, output_dir=\"./results/es_mbert_aeda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Previous Evaluation","metadata":{}},{"cell_type":"code","source":"# Run inference on each tweet\noutput = []\nfor case_id, case_data in tqdm(test_data.items()):\n    if case_data['lang']=='es':\n        continue\n    tweet = case_data[\"tweet\"]\n\n    # Tokenize the tweet\n    inputs = tokenizer(tweet, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n    # Ensure the model and inputs are on the same device (use GPU if available)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    inputs = {key: val.to(device) for key, val in inputs.items()}\n\n    # Get model predictions\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Get the predicted class index\n    logits = outputs.logits\n    predicted_class_idx = torch.argmax(logits, dim=1).item()\n\n    # Map the predicted class index to label\n    predicted_label = id2label[predicted_class_idx]\n\n    # Append the result to the output list\n    output.append({\n        \"test_case\": \"EXIST2025\",\n        \"id\": case_data[\"id_EXIST\"],\n        \"value\": predicted_label\n    })\n\n# Save the results to an output JSON file\noutput_json_file = \"distil_en_hard_predictions_mergedlang.json\"  # Specify the output file path\nwith open(output_json_file, \"w\") as f:\n    json.dump(output, f, indent=4)\n\nprint(f\"Results saved to {output_json_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:25:30.269160Z","iopub.execute_input":"2025-04-23T07:25:30.269506Z","iopub.status.idle":"2025-04-23T07:25:33.464760Z","shell.execute_reply.started":"2025-04-23T07:25:30.269476Z","shell.execute_reply":"2025-04-23T07:25:33.463852Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1038/1038 [00:03<00:00, 326.52it/s]","output_type":"stream"},{"name":"stdout","text":"Results saved to distil_en_hard_predictions_mergedlang.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"from pyevall.evaluation import PyEvALLEvaluation\nfrom pyevall.utils.utils import PyEvALLUtils\npredictions = \"/kaggle/working/distil_en_hard_predictions_mergedlang.json\"         \ngold = \"/kaggle/input/existdatasets/EXIST2025_dev_task1_2_gold_hard.json\" \ntest = PyEvALLEvaluation() \nparams= dict() \nparams[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED  \nmetrics=[\"ICM\", \"ICMNorm\" ,\"FMeasure\"]                  # for hard        \nreport= test.evaluate(predictions, gold, metrics, **params) \nreport.print_report()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:25:37.553418Z","iopub.execute_input":"2025-04-23T07:25:37.553707Z","iopub.status.idle":"2025-04-23T07:25:38.963461Z","shell.execute_reply.started":"2025-04-23T07:25:37.553684Z","shell.execute_reply":"2025-04-23T07:25:38.962616Z"}},"outputs":[{"name":"stdout","text":"2025-04-23 07:25:37,560 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n2025-04-23 07:25:37,647 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n2025-04-23 07:25:37,954 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n2025-04-23 07:25:37,957 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n2025-04-23 07:25:38,265 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n2025-04-23 07:25:38,664 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n{\n  \"metrics\": {\n    \"ICM\": {\n      \"name\": \"Information Contrast model\",\n      \"acronym\": \"ICM\",\n      \"description\": \"Coming soon!\",\n      \"status\": \"OK\",\n      \"results\": {\n        \"test_cases\": [{\n          \"name\": \"EXIST2025\",\n          \"average\": -1.0473823352220666\n        }],\n        \"average_per_test_case\": -1.0473823352220666\n      }\n    },\n    \"ICMNorm\": {\n      \"name\": \"Normalized Information Contrast Model\",\n      \"acronym\": \"ICM-Norm\",\n      \"description\": \"Coming soon!\",\n      \"status\": \"OK\",\n      \"results\": {\n        \"test_cases\": [{\n          \"name\": \"EXIST2025\",\n          \"average\": 0.17247400070251906\n        }],\n        \"average_per_test_case\": 0.17247400070251906\n      }\n    },\n    \"FMeasure\": {\n      \"name\": \"F-Measure\",\n      \"acronym\": \"F1\",\n      \"description\": \"Coming soon!\",\n      \"status\": \"OK\",\n      \"results\": {\n        \"test_cases\": [{\n          \"name\": \"EXIST2025\",\n          \"classes\": {\n            \"JUDGEMENTAL\": 0,\n            \"NO\": 0.5762273901808785,\n            \"REPORTED\": 0.16417910447761194,\n            \"DIRECT\": 0.3480825958702065\n          },\n          \"average\": 0.27212227263217426\n        }],\n        \"average_per_test_case\": 0.27212227263217426\n      }\n    }\n  },\n  \"files\": {\n    \"distil_en_hard_predictions_mergedlang.json\": {\n      \"name\": \"distil_en_hard_predictions_mergedlang.json\",\n      \"status\": \"OK\",\n      \"gold\": false,\n      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: distil_en_hard_predictions_mergedlang.json.\",\n      \"errors\": {}\n    },\n    \"EXIST2025_dev_task1_2_gold_hard.json\": {\n      \"name\": \"EXIST2025_dev_task1_2_gold_hard.json\",\n      \"status\": \"OK\",\n      \"gold\": true,\n      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_task1_2_gold_hard.json.\",\n      \"errors\": {}\n    }\n  }\n}\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"soft","metadata":{}},{"cell_type":"code","source":"import torch\nimport json\nfrom tqdm import tqdm\noutput = []\n\n# Run inference on each tweet\nfor case_id, case_data in tqdm(test_data.items()):\n    if case_data['lang']=='es':\n        continue\n\n    tweet = case_data[\"tweet\"]\n\n    # Tokenize the tweet\n    inputs = tokenizer(tweet, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n    # Ensure the model and inputs are on the same device (use GPU if available)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    inputs = {key: val.to(device) for key, val in inputs.items()}\n\n    # Get model predictions\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Get probabilities for all labels\n    logits = outputs.logits\n    probabilities = torch.nn.functional.softmax(logits, dim=1).squeeze().tolist()\n    # print(probabilities)\n    # Map class indices to labels with probabilities\n    label_probs = {id2label[idx]: prob for idx, prob in enumerate(probabilities)}\n    values = {\n            \"NO\": label_probs[\"NO\"],\n            \"REPORTED\": label_probs[\"REPORTED\"],\n            \"JUDGEMENTAL\": label_probs[\"JUDGEMENTAL\"],\n            \"DIRECT\": label_probs[\"DIRECT\"],\n        }\n    # Append the result to the output list\n    output.append({\n        \"test_case\": \"EXIST2025\",\n        \"id\": str(case_data[\"id_EXIST\"]),\n        \"value\": dict(sorted(values.items(), key=lambda item: item[1]))\n    })\n\n# Save the results to an output JSON file\noutput_json_file = \"distil_en_soft_predictions_mergedlang.json\"  # Specify the output file path\nwith open(output_json_file, \"w\") as f:\n    json.dump(output, f, indent=4)\n\nprint(f\"Results saved to {output_json_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:27:23.826617Z","iopub.execute_input":"2025-04-23T07:27:23.827020Z","iopub.status.idle":"2025-04-23T07:27:27.019772Z","shell.execute_reply.started":"2025-04-23T07:27:23.826987Z","shell.execute_reply":"2025-04-23T07:27:27.018838Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1038/1038 [00:03<00:00, 327.55it/s]","output_type":"stream"},{"name":"stdout","text":"Results saved to distil_en_soft_predictions_mergedlang.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"softs = pd.read_json(\"distil_en_soft_predictions_mergedlang.json\")\nsofts.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:34:55.682564Z","iopub.execute_input":"2025-04-23T07:34:55.682909Z","iopub.status.idle":"2025-04-23T07:34:55.700616Z","shell.execute_reply.started":"2025-04-23T07:34:55.682857Z","shell.execute_reply":"2025-04-23T07:34:55.699971Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"   test_case      id                                              value\n0  EXIST2025  400001  {'JUDGEMENTAL': 0.120749652385711, 'REPORTED':...\n1  EXIST2025  400002  {'NO': 0.187171712517738, 'JUDGEMENTAL': 0.224...\n2  EXIST2025  400003  {'NO': 0.176499783992767, 'JUDGEMENTAL': 0.213...\n3  EXIST2025  400004  {'REPORTED': 0.007521138526499001, 'JUDGEMENTA...\n4  EXIST2025  400005  {'DIRECT': 0.013363457284867, 'JUDGEMENTAL': 0...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_case</th>\n      <th>id</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EXIST2025</td>\n      <td>400001</td>\n      <td>{'JUDGEMENTAL': 0.120749652385711, 'REPORTED':...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EXIST2025</td>\n      <td>400002</td>\n      <td>{'NO': 0.187171712517738, 'JUDGEMENTAL': 0.224...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>EXIST2025</td>\n      <td>400003</td>\n      <td>{'NO': 0.176499783992767, 'JUDGEMENTAL': 0.213...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>EXIST2025</td>\n      <td>400004</td>\n      <td>{'REPORTED': 0.007521138526499001, 'JUDGEMENTA...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EXIST2025</td>\n      <td>400005</td>\n      <td>{'DIRECT': 0.013363457284867, 'JUDGEMENTAL': 0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"from pyevall.evaluation import PyEvALLEvaluation\nfrom pyevall.utils.utils import PyEvALLUtils\npredictions = \"/kaggle/working/distil_en_soft_predictions_mergedlang.json\"         \ngold = \"/kaggle/input/existdatasets/EXIST2025_dev_task1_2_soft_hard.json\" \ntest = PyEvALLEvaluation() \nparams= dict() \nparams[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED  \nmetrics=[\"ICMSoft\", \"ICMSoftNorm\", \"CrossEntropy\"]      # for soft    \nreport= test.evaluate(predictions, gold, metrics, **params) \nreport.print_report()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:31:24.295705Z","iopub.execute_input":"2025-04-23T07:31:24.296067Z","iopub.status.idle":"2025-04-23T07:31:24.315740Z","shell.execute_reply.started":"2025-04-23T07:31:24.296039Z","shell.execute_reply":"2025-04-23T07:31:24.314816Z"}},"outputs":[{"name":"stdout","text":"2025-04-23 07:31:24,302 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICMSoft', 'ICMSoftNorm', 'CrossEntropy']\n{\n  \"metrics\": {},\n  \"files\": {\n    \"distil_en_soft_predictions_mergedlang.json\": {\n      \"name\": \"distil_en_soft_predictions_mergedlang.json\",\n      \"status\": \"OK\",\n      \"gold\": false,\n      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: distil_en_soft_predictions_mergedlang.json.\",\n      \"errors\": {}\n    },\n    \"EXIST2025_dev_task1_2_soft_hard.json\": {\n      \"name\": \"EXIST2025_dev_task1_2_soft_hard.json\",\n      \"status\": \"FAIL\",\n      \"gold\": true,\n      \"description\": \"The file contains errors or warnings, please review them.\\\\nFile name: EXIST2025_dev_task1_2_soft_hard.json.\",\n      \"errors\": {\n        \"FORMAT_FILE_NOT_EXIST_ERROR\": {\n          \"description\": \"File not found error: wrong file's path.\\\\nFile name: EXIST2025_dev_task1_2_soft_hard.json.\\\\nThe evaluation STOP.\",\n          \"exception\": null,\n          \"status\": \"STOP\"\n        }\n      }\n    }\n  }\n}\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"## Free up working dir","metadata":{}},{"cell_type":"code","source":"# Clear output folder\nimport os\n\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working/results/es_mbert_aeda'\nremove_folder_contents(folder_path)\nos.rmdir(folder_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:42:27.858797Z","iopub.execute_input":"2025-04-24T09:42:27.859462Z","iopub.status.idle":"2025-04-24T09:42:27.919200Z","shell.execute_reply.started":"2025-04-24T09:42:27.859437Z","shell.execute_reply":"2025-04-24T09:42:27.918429Z"}},"outputs":[],"execution_count":4}]}